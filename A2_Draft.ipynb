{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faithrts/COMP-551/blob/main/A2_Draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set-up"
      ],
      "metadata": {
        "id": "8A1SE2icjh69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VCTCTWgB-NKG"
      },
      "outputs": [],
      "source": [
        "### importing libraries and setting the random seed\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import re\n",
        "import math\n",
        "import bisect\n",
        "from scipy.stats import zscore\n",
        "from scipy.io import arff\n",
        "from importlib import reload\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split as skl_train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "# a folder to store the saved graphs\n",
        "#!mkdir images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Handling"
      ],
      "metadata": {
        "id": "hKHZWj9vjn1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing"
      ],
      "metadata": {
        "id": "FsaKjKTqjylr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrnSxLmFTCp9",
        "outputId": "7378b61c-1cea-4b43-8447-2ce3cc699b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-25 18:40:34--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  52.2MB/s    in 1.5s    \n",
            "\n",
            "2022-10-25 18:40:35 (52.2 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### importing the files from the web to google colab\n",
        "\n",
        "# retrieving the IMDB data\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "\n",
        "# unzipping the tar.gz file into google colab for easy access\n",
        "!tar -xf  'aclImdb_v1.tar.gz'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "YLKtKHXfky5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "MtAHDLEXj2T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and cleaning IMDB data"
      ],
      "metadata": {
        "id": "HQbCrZx0-EgM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "myJJchNbcsCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and cleaning 20 News Groups"
      ],
      "metadata": {
        "id": "bPtGybWIk_HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### selecting 4 categories and extracting the data from sklearn\n",
        "\n",
        "fav_four = ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.politics.guns']\n",
        "\n",
        "# 20 news groups training\n",
        "twenty_train = fetch_20newsgroups(subset='train', categories=fav_four, remove=(['headers', 'footers', 'quotes']))\n",
        "# 20 news groups testing\n",
        "twenty_test = fetch_20newsgroups(subset='test', categories=fav_four, remove=(['headers', 'footers', 'quotes']))"
      ],
      "metadata": {
        "id": "3WqzrGinX5h-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1ur2Y9mBZu25"
      },
      "outputs": [],
      "source": [
        "### transforming the data into vectors\n",
        "\n",
        "# creating a new CountVectorizer object\n",
        "count_vect = CountVectorizer(max_df=0.5, min_df=0.01)\n",
        "\n",
        "# builds a dictionary of features and transforms documents to feature\n",
        "# vectors where each index represents the occurrence of a specific word\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "\n",
        "# creating a dataframe in which row represents a document and each column\n",
        "# a word\n",
        "X_train_arr = pd.DataFrame(X_train_counts.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing models"
      ],
      "metadata": {
        "id": "a6lVueablnwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "U_WEPKULlIU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression"
      ],
      "metadata": {
        "id": "-7B0imbhlxBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-class regression"
      ],
      "metadata": {
        "id": "vFWDVUnTl3gR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running experiments"
      ],
      "metadata": {
        "id": "IlELJSq3nWUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "0rywH03KE_9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression experiments"
      ],
      "metadata": {
        "id": "SNenEnbonsLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline accuracy tests"
      ],
      "metadata": {
        "id": "v2F28zoKwHvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-class regression experiments"
      ],
      "metadata": {
        "id": "MPKaxl_Ynx2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline accuracy tests\n"
      ],
      "metadata": {
        "id": "_Wj_V05NvwBf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}