{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faithrts/COMP-551/blob/main/A1_Draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set-up"
      ],
      "metadata": {
        "id": "8A1SE2icjh69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VCTCTWgB-NKG"
      },
      "outputs": [],
      "source": [
        "### importing libraries and setting the random seed\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import bisect\n",
        "from scipy.stats import zscore\n",
        "from scipy.io import arff\n",
        "from importlib import reload\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Handling"
      ],
      "metadata": {
        "id": "hKHZWj9vjn1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing"
      ],
      "metadata": {
        "id": "FsaKjKTqjylr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrnSxLmFTCp9",
        "outputId": "7d0c7652-a7d7-4224-c534-f0e423b8b4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-08 18:12:52--  http://archive.ics.uci.edu/ml/machine-learning-databases/hepatitis/hepatitis.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7545 (7.4K) [application/x-httpd-php]\n",
            "Saving to: ‘hepatitis.data’\n",
            "\n",
            "\rhepatitis.data        0%[                    ]       0  --.-KB/s               \rhepatitis.data      100%[===================>]   7.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-08 18:12:52 (487 MB/s) - ‘hepatitis.data’ saved [7545/7545]\n",
            "\n",
            "--2022-10-08 18:12:52--  https://archive.ics.uci.edu/ml/machine-learning-databases/00329/messidor_features.arff\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117224 (114K) [application/x-httpd-php]\n",
            "Saving to: ‘messidor_features.arff’\n",
            "\n",
            "messidor_features.a 100%[===================>] 114.48K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-10-08 18:12:52 (1.39 MB/s) - ‘messidor_features.arff’ saved [117224/117224]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### importing the files from the web to google colab\n",
        "\n",
        "# hepatitis.data\n",
        "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/hepatitis/hepatitis.data\n",
        "\n",
        "# messidor_features.arff\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00329/messidor_features.arff"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preproccessing"
      ],
      "metadata": {
        "id": "MtAHDLEXj2T3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C4jhNoIpYEpq"
      },
      "outputs": [],
      "source": [
        "### computing zcore to remove outlier data\n",
        "\n",
        "def remove_outliers(df):\n",
        "  abs_z_scores = np.abs(df.apply(zscore))\n",
        "  filtered_df = (abs_z_scores < 3).all(axis = 1)\n",
        "  return df[filtered_df]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hBDZ8Cxhb_mk"
      },
      "outputs": [],
      "source": [
        "# helper function to aid in normalizing dataframes\n",
        "def normalize_array(arr):\n",
        "  normalized_array = []\n",
        "\n",
        "  for i in arr:\n",
        "    new_val = (i - min(arr)) / (max(arr) - min(arr))\n",
        "    normalized_array.append(new_val)\n",
        "\n",
        "  return normalized_array\n",
        "\n",
        "# function to normalize dataframes; assumes first column is the target labels\n",
        "def normalize_df(df):\n",
        "  normalized_df = df.copy()\n",
        "\n",
        "  for col in df.iloc[:, 1:]:\n",
        "    normalized_col = normalize_array(df[col])\n",
        "    normalized_df[col] = normalized_col\n",
        "\n",
        "  return normalized_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pkh23nL0rokB"
      },
      "outputs": [],
      "source": [
        "# assumes first column is the target labels\n",
        "def standardize_df(df):\n",
        "  standardized_df = df.copy()\n",
        "\n",
        "  for col in df.iloc[:, 1:]:\n",
        "\n",
        "    mean_val = df[col].mean()\n",
        "    standard_dev = df[col].std()\n",
        "\n",
        "    standardized_df[col] = (df[col] - mean_val) / standard_dev\n",
        "\n",
        "  return standardized_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hepatitis "
      ],
      "metadata": {
        "id": "YLKtKHXfky5X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "vOfc6iLH_ZQ8"
      },
      "outputs": [],
      "source": [
        "### creating the dataframe for hepatitis.data\n",
        "\n",
        "# creates a dataframe from the .data file\n",
        "hep_df = pd.read_csv(\"hepatitis.data\", sep=\",\", header=None)\n",
        "\n",
        "# the column names\n",
        "hep_cols = ['CLASS', 'AGE', 'SEX', 'STEROID','ANTIVIRALS', 'FATIGUE',\n",
        "            'MALAISE', 'ANOREXIA', 'LIVER BIG', 'LIVER FIRM',\n",
        "            'SPLEEN PALPABLE', 'SPIDERS', 'ASCITES', 'VARICES',\n",
        "            'BILIRUBIN', 'ALK PHOSPHATE', 'SGOT', 'ALBUMIN',\n",
        "            'PROTIME', 'HISTOLOGY']\n",
        "\n",
        "# adds the column names to the dataframe\n",
        "hep_df.columns = hep_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "urN0iK66trvg"
      },
      "outputs": [],
      "source": [
        "### creating lists to separate the names of columns containing\n",
        "### boolean values vs the ones containing continuous values\n",
        "\n",
        "bool_col = ['CLASS', 'SEX', 'STEROID', 'ANTIVIRALS', 'FATIGUE',\n",
        "            'MALAISE', 'ANOREXIA', 'LIVER BIG', 'LIVER FIRM',\n",
        "            'SPLEEN PALPABLE', 'SPIDERS', 'ASCITES', 'VARICES',\n",
        "            'HISTOLOGY']\n",
        "\n",
        "non_bool_col = ['AGE', 'BILIRUBIN', 'ALK PHOSPHATE', 'SGOT', 'ALBUMIN', 'PROTIME']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8zQbSQRFu_D5"
      },
      "outputs": [],
      "source": [
        "### cleaning hepatitis dataframe\n",
        "\n",
        "# saves a copy of the dataframe without rows that include '?' values\n",
        "intact_rows = hep_df[~hep_df.eq('?').any(axis=1)].astype('float')\n",
        "\n",
        "# iterates through columns with boolean values\n",
        "for col in bool_col:\n",
        "\n",
        "  # replaces instances of 1.0 and 2.0 with the boolean integers 0 and 1\n",
        "  intact_rows[col] = intact_rows[col].replace({1.0:0, 2.0:1})\n",
        "  # calculates the mode of the current column (ignores '?')\n",
        "  mode = int(intact_rows[col].mode()[0])\n",
        "\n",
        "  # in the original dataframe, replaces each '?' with the column's mode\n",
        "  hep_df[col] = hep_df[col].replace({'?': mode}).astype('int64')\n",
        "  # in the original dataframe, replaces 1.0 and 2.0 with boolean ints 0 and 1\n",
        "  hep_df[col] = hep_df[col].replace({1.0:0, 2.0:1})\n",
        "\n",
        "# iterates through columns with non-boolean values\n",
        "for col in non_bool_col:\n",
        "  # calculates the mean of the current column (ignores '?')\n",
        "  mean = intact_rows[col].mean()\n",
        "  # in the original dataframe, replaces each '?' with the column's mean\n",
        "  hep_df[col] = hep_df[col].replace({'?': mean}).astype('float')\n",
        "\n",
        "hep_df = remove_outliers(hep_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xJ3aymdzhd5Y",
        "outputId": "a4d89ca6-e923-47eb-aa71-c8901ace26c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     CLASS   AGE  SEX  STEROID  ANTIVIRALS  FATIGUE  MALAISE  ANOREXIA  \\\n",
              "0        1  30.0    1        0           1        1        1         1   \n",
              "1        1  50.0    0        0           1        0        1         1   \n",
              "2        1  78.0    0        1           1        0        1         1   \n",
              "3        1  31.0    0        0           0        1        1         1   \n",
              "4        1  34.0    0        1           1        1        1         1   \n",
              "..     ...   ...  ...      ...         ...      ...      ...       ...   \n",
              "149      1  36.0    0        1           1        1        1         1   \n",
              "151      1  44.0    0        1           1        0        1         1   \n",
              "152      1  61.0    0        0           1        0        0         1   \n",
              "153      1  53.0    1        0           1        0        1         1   \n",
              "154      0  43.0    0        1           1        0        1         1   \n",
              "\n",
              "     LIVER BIG  LIVER FIRM  SPLEEN PALPABLE  SPIDERS  ASCITES  VARICES  \\\n",
              "0            0           1                1        1        1        1   \n",
              "1            0           1                1        1        1        1   \n",
              "2            1           1                1        1        1        1   \n",
              "3            1           1                1        1        1        1   \n",
              "4            1           1                1        1        1        1   \n",
              "..         ...         ...              ...      ...      ...      ...   \n",
              "149          1           1                1        1        1        1   \n",
              "151          1           0                1        1        1        1   \n",
              "152          0           0                1        0        1        1   \n",
              "153          1           1                0        0        1        0   \n",
              "154          1           1                0        0        0        1   \n",
              "\n",
              "     BILIRUBIN  ALK PHOSPHATE   SGOT  ALBUMIN  PROTIME  HISTOLOGY  \n",
              "0          1.0        85.0000   18.0      4.0  62.5125          0  \n",
              "1          0.9       135.0000   42.0      3.5  62.5125          0  \n",
              "2          0.7        96.0000   32.0      4.0  62.5125          0  \n",
              "3          0.7        46.0000   52.0      4.0  80.0000          0  \n",
              "4          1.0       102.9125  200.0      4.0  62.5125          0  \n",
              "..         ...            ...    ...      ...      ...        ...  \n",
              "149        0.6       120.0000   30.0      4.0  62.5125          1  \n",
              "151        0.9       126.0000  142.0      4.3  62.5125          1  \n",
              "152        0.8        75.0000   20.0      4.1  62.5125          1  \n",
              "153        1.5        81.0000   19.0      4.1  48.0000          1  \n",
              "154        1.2       100.0000   19.0      3.1  42.0000          1  \n",
              "\n",
              "[145 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20fc8537-1e74-4225-95d8-b044129e9968\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>AGE</th>\n",
              "      <th>SEX</th>\n",
              "      <th>STEROID</th>\n",
              "      <th>ANTIVIRALS</th>\n",
              "      <th>FATIGUE</th>\n",
              "      <th>MALAISE</th>\n",
              "      <th>ANOREXIA</th>\n",
              "      <th>LIVER BIG</th>\n",
              "      <th>LIVER FIRM</th>\n",
              "      <th>SPLEEN PALPABLE</th>\n",
              "      <th>SPIDERS</th>\n",
              "      <th>ASCITES</th>\n",
              "      <th>VARICES</th>\n",
              "      <th>BILIRUBIN</th>\n",
              "      <th>ALK PHOSPHATE</th>\n",
              "      <th>SGOT</th>\n",
              "      <th>ALBUMIN</th>\n",
              "      <th>PROTIME</th>\n",
              "      <th>HISTOLOGY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>85.0000</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>62.5125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>135.0000</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>62.5125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>96.0000</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>62.5125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>46.0000</td>\n",
              "      <td>52.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>80.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>102.9125</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>62.5125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>1</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>120.0000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>62.5125</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>1</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>126.0000</td>\n",
              "      <td>142.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>62.5125</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>1</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>75.0000</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>62.5125</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>1</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>81.0000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>48.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>100.0000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>42.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>145 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20fc8537-1e74-4225-95d8-b044129e9968')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20fc8537-1e74-4225-95d8-b044129e9968 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20fc8537-1e74-4225-95d8-b044129e9968');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "hep_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of hepatitis data"
      ],
      "metadata": {
        "id": "NMKBKMJYkSAk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r8Xhobsvxrq5",
        "outputId": "f6cb9ccd-9b58-4e38-b157-a92ea1fea1ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            CLASS\n",
              "ALBUMIN  0.464922\n",
              "ASCITES  0.409313\n",
              "SPIDERS  0.390570"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e776d973-7977-49d3-b712-efe2b0a80cfd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ALBUMIN</th>\n",
              "      <td>0.464922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ASCITES</th>\n",
              "      <td>0.409313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SPIDERS</th>\n",
              "      <td>0.390570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e776d973-7977-49d3-b712-efe2b0a80cfd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e776d973-7977-49d3-b712-efe2b0a80cfd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e776d973-7977-49d3-b712-efe2b0a80cfd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "### finding the most correlated features with CLASS column (target)\n",
        "\n",
        "# creates correlation dataframe\n",
        "correlation_df = hep_df.corr()\n",
        "\n",
        "# removes the first row of the correlation dataframe\n",
        "class_correlation = (correlation_df).iloc[1:, 0:1]\n",
        "\n",
        "# finds the 3 largest values (the 3 features most positively \n",
        "# correlated with CLASS)\n",
        "pos_correlation = class_correlation.nlargest(3, 'CLASS')\n",
        "\n",
        "# show the 3 features most positively correlated with target labels\n",
        "pos_correlation.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FoG4YU8_w6VB",
        "outputId": "895ad613-1b12-4576-b990-0ce7e7f4f944"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              CLASS\n",
              "BILIRUBIN -0.403335\n",
              "HISTOLOGY -0.354126\n",
              "AGE       -0.208460"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd0a9d36-853f-49b4-a74c-46c14dfe73d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BILIRUBIN</th>\n",
              "      <td>-0.403335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HISTOLOGY</th>\n",
              "      <td>-0.354126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>-0.208460</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd0a9d36-853f-49b4-a74c-46c14dfe73d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd0a9d36-853f-49b4-a74c-46c14dfe73d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd0a9d36-853f-49b4-a74c-46c14dfe73d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# finds the 3 smallest values (the 3 features most negatively\n",
        "# correlated with CLASS)\n",
        "neg_correlation = class_correlation.nsmallest(3, 'CLASS')\n",
        "\n",
        "# show the 3 features most negatively correlated with target labels\n",
        "neg_correlation.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FH48NeSWTeJG",
        "outputId": "829e4212-cfa0-4256-f627-0d064a70594d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "### creating histograms for columns with non-boolean values\n",
        "\n",
        "for col in non_bool_col:\n",
        "  hep_df.hist(column = col, figsize = (3,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Messidor Features"
      ],
      "metadata": {
        "id": "bPtGybWIk_HV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1ur2Y9mBZu25"
      },
      "outputs": [],
      "source": [
        "### creating the dataframe for messidor_features.arff\n",
        "\n",
        "# loads in the arff data\n",
        "mess_data = arff.loadarff('messidor_features.arff')\n",
        "# creates a dataframe from the .arff file\n",
        "mess_df = pd.DataFrame(mess_data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "srPnmzdFoCDO"
      },
      "outputs": [],
      "source": [
        "### cleaning the data in mess_df\n",
        "\n",
        "# columns with boolean values\n",
        "bool_cols = ['0', '1', '18']\n",
        "\n",
        "# ensures the columns with boolean values save as integers\n",
        "for col in bool_cols:\n",
        "  mess_df[col] = mess_df[col].astype('int64')\n",
        "\n",
        "# resaving the boolean values in the Class column from objects to ints\n",
        "mess_df['Class'] = mess_df['Class'].map({b'0':0, b'1':1}).astype('int64')\n",
        "\n",
        "mess_df = remove_outliers(mess_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UCeBz6rJpfnp",
        "outputId": "9e443ad7-0574-475e-da28-35b390d05cd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0  1     2     3     4     5     6     7          8          9  \\\n",
              "0     1  1  22.0  22.0  22.0  19.0  18.0  14.0  49.895756  17.775994   \n",
              "1     1  1  24.0  24.0  22.0  18.0  16.0  13.0  57.709936  23.799994   \n",
              "2     1  1  62.0  60.0  59.0  54.0  47.0  33.0  55.831441  27.993933   \n",
              "3     1  1  55.0  53.0  53.0  50.0  43.0  31.0  40.467228  18.445954   \n",
              "4     1  1  44.0  44.0  44.0  41.0  39.0  27.0  18.026254   8.570709   \n",
              "...  .. ..   ...   ...   ...   ...   ...   ...        ...        ...   \n",
              "1144  1  1  35.0  34.0  33.0  33.0  33.0  26.0   2.579859   0.001552   \n",
              "1146  1  1  34.0  34.0  34.0  33.0  31.0  24.0   6.071765   0.937472   \n",
              "1147  1  1  49.0  49.0  49.0  49.0  45.0  37.0  63.197145  27.377668   \n",
              "1149  1  1  39.0  36.0  29.0  23.0  13.0   7.0  40.525739  12.604947   \n",
              "1150  1  1   7.0   7.0   7.0   7.0   7.0   5.0  69.423565   7.031843   \n",
              "\n",
              "             10        11        12        13        14        15        16  \\\n",
              "0      5.270920  0.771761  0.018632  0.006864  0.003923  0.003923  0.486903   \n",
              "1      3.325423  0.234185  0.003903  0.003903  0.003903  0.003903  0.520908   \n",
              "2     12.687485  4.852282  1.393889  0.373252  0.041817  0.007744  0.530904   \n",
              "3      9.118901  3.079428  0.840261  0.272434  0.007653  0.001531  0.483284   \n",
              "4      0.410381  0.000000  0.000000  0.000000  0.000000  0.000000  0.475935   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "1144   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.537551   \n",
              "1146   0.031145  0.003115  0.000000  0.000000  0.000000  0.000000  0.537470   \n",
              "1147   8.067688  0.979548  0.001552  0.000000  0.000000  0.000000  0.516733   \n",
              "1149   4.740919  1.077570  0.563518  0.326860  0.239568  0.174584  0.485972   \n",
              "1150   1.750548  0.046597  0.021180  0.008472  0.000000  0.000000  0.556192   \n",
              "\n",
              "            17  18  Class  \n",
              "0     0.100025   1      0  \n",
              "1     0.144414   0      0  \n",
              "2     0.128548   0      1  \n",
              "3     0.114790   0      0  \n",
              "4     0.123572   0      1  \n",
              "...        ...  ..    ...  \n",
              "1144  0.124181   0      0  \n",
              "1146  0.116795   0      0  \n",
              "1147  0.124190   0      0  \n",
              "1149  0.106690   1      1  \n",
              "1150  0.088957   0      0  \n",
              "\n",
              "[968 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf4360a1-834b-4a9b-a00f-7251b2e9f133\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>49.895756</td>\n",
              "      <td>17.775994</td>\n",
              "      <td>5.270920</td>\n",
              "      <td>0.771761</td>\n",
              "      <td>0.018632</td>\n",
              "      <td>0.006864</td>\n",
              "      <td>0.003923</td>\n",
              "      <td>0.003923</td>\n",
              "      <td>0.486903</td>\n",
              "      <td>0.100025</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>57.709936</td>\n",
              "      <td>23.799994</td>\n",
              "      <td>3.325423</td>\n",
              "      <td>0.234185</td>\n",
              "      <td>0.003903</td>\n",
              "      <td>0.003903</td>\n",
              "      <td>0.003903</td>\n",
              "      <td>0.003903</td>\n",
              "      <td>0.520908</td>\n",
              "      <td>0.144414</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>62.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>55.831441</td>\n",
              "      <td>27.993933</td>\n",
              "      <td>12.687485</td>\n",
              "      <td>4.852282</td>\n",
              "      <td>1.393889</td>\n",
              "      <td>0.373252</td>\n",
              "      <td>0.041817</td>\n",
              "      <td>0.007744</td>\n",
              "      <td>0.530904</td>\n",
              "      <td>0.128548</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>55.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>40.467228</td>\n",
              "      <td>18.445954</td>\n",
              "      <td>9.118901</td>\n",
              "      <td>3.079428</td>\n",
              "      <td>0.840261</td>\n",
              "      <td>0.272434</td>\n",
              "      <td>0.007653</td>\n",
              "      <td>0.001531</td>\n",
              "      <td>0.483284</td>\n",
              "      <td>0.114790</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>44.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>18.026254</td>\n",
              "      <td>8.570709</td>\n",
              "      <td>0.410381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.475935</td>\n",
              "      <td>0.123572</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1144</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.579859</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.537551</td>\n",
              "      <td>0.124181</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1146</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>6.071765</td>\n",
              "      <td>0.937472</td>\n",
              "      <td>0.031145</td>\n",
              "      <td>0.003115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.537470</td>\n",
              "      <td>0.116795</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>63.197145</td>\n",
              "      <td>27.377668</td>\n",
              "      <td>8.067688</td>\n",
              "      <td>0.979548</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.516733</td>\n",
              "      <td>0.124190</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>40.525739</td>\n",
              "      <td>12.604947</td>\n",
              "      <td>4.740919</td>\n",
              "      <td>1.077570</td>\n",
              "      <td>0.563518</td>\n",
              "      <td>0.326860</td>\n",
              "      <td>0.239568</td>\n",
              "      <td>0.174584</td>\n",
              "      <td>0.485972</td>\n",
              "      <td>0.106690</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1150</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>69.423565</td>\n",
              "      <td>7.031843</td>\n",
              "      <td>1.750548</td>\n",
              "      <td>0.046597</td>\n",
              "      <td>0.021180</td>\n",
              "      <td>0.008472</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.556192</td>\n",
              "      <td>0.088957</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>968 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf4360a1-834b-4a9b-a00f-7251b2e9f133')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf4360a1-834b-4a9b-a00f-7251b2e9f133 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf4360a1-834b-4a9b-a00f-7251b2e9f133');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "mess_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of Messidor Features"
      ],
      "metadata": {
        "id": "D8VpXlUdlYqZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "V5VG0TEC8dCi",
        "outputId": "f5f5208e-29ce-4974-dd2a-ba0417a1e5fe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Class'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ec648b1d83a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# finds the 3 largest values (the 3 features most positively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# correlated with CLASS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpos_correlation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_correlation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# show the 3 features most positively correlated with target labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mnlargest\u001b[0;34m(self, n, columns, keep)\u001b[0m\n\u001b[1;32m   6634\u001b[0m         \u001b[0mBrunei\u001b[0m      \u001b[0;36m434000\u001b[0m    \u001b[0;36m12128\u001b[0m      \u001b[0mBN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6635\u001b[0m         \"\"\"\n\u001b[0;32m-> 6636\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSelectNFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnsmallest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"first\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mnlargest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1219\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nlargest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid_dtype_n_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Class'"
          ]
        }
      ],
      "source": [
        "### finding the most correlated features with Class column (target)\n",
        "\n",
        "# creates correlation dataframe\n",
        "correlation_df = mess_df.corr()\n",
        "\n",
        "# removes the first row of the correlation dataframe\n",
        "class_correlation = (correlation_df).iloc[1:, 0:1]\n",
        "\n",
        "# finds the 3 largest values (the 3 features most positively \n",
        "# correlated with CLASS)\n",
        "pos_correlation = class_correlation.nlargest(3, 'Class')\n",
        "\n",
        "# show the 3 features most positively correlated with target labels\n",
        "pos_correlation.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPodfhivxHCi"
      },
      "outputs": [],
      "source": [
        "# finds the 3 smallest values (the 3 features most negatively\n",
        "# correlated with CLASS)\n",
        "neg_correlation = class_correlation.nsmallest(3, 'Class')\n",
        "\n",
        "# show the 3 features most negatively correlated with target labels\n",
        "neg_correlation.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhDvfz6WIpwp"
      },
      "outputs": [],
      "source": [
        "### creating histograms for each value\n",
        "\n",
        "for col in mess_df:\n",
        "  if col != \"Class\":\n",
        "    mess_df.hist(column = col, figsize = (3,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "U_WEPKULlIU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NaSHTl-L7WfU"
      },
      "outputs": [],
      "source": [
        "### function to split the data\n",
        "\n",
        "# assumes the first column of the df is the target label\n",
        "def train_test_split(df):\n",
        "\n",
        "  # shuffling the order of rows in the input dataframe\n",
        "  df = df.sample(frac = 1, random_state = 1)\n",
        "\n",
        "  # splits the input dataframe into arrays of instances and labels\n",
        "  x, y = df.iloc[:, 1:].to_numpy(), df.iloc[:, 0].to_numpy()\n",
        "\n",
        "  # the number of data points\n",
        "  instance_count = x.shape[0]\n",
        "\n",
        "  # the number of instances to be used in the training data\n",
        "  train_count = int((instance_count/3)*2)\n",
        "\n",
        "  # splitting the data into training data and labels,\n",
        "  # and testing data and labels\n",
        "  x_train, y_train = x[:train_count], y[:train_count]\n",
        "  x_test, y_test = x[train_count:], y[train_count:]\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_s60NJiriwJK"
      },
      "outputs": [],
      "source": [
        "### accuracy-evaluating function\n",
        "\n",
        "def evaluate_acc(true_labels, target_labels):\n",
        "\n",
        "  # the number of labels\n",
        "  label_count = true_labels.shape[0]\n",
        "\n",
        "  # the accuracy is the number of correctly labelled instances\n",
        "  # divided by the total amount\n",
        "  accuracy = np.sum(true_labels == target_labels)/label_count\n",
        "\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing models"
      ],
      "metadata": {
        "id": "a6lVueablnwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "-7B0imbhlxBQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2aSftjetWRzc"
      },
      "outputs": [],
      "source": [
        "# distance functions\n",
        "euclidean = lambda x_train, x_test: np.sqrt(np.sum((x_train - x_test)**2, axis = -1))\n",
        "manhattan = lambda x_train, x_test: np.sum(np.abs(x_train - x_test), axis = -1)\n",
        "cosine = lambda x_train, x_test: np.sum(x_train * x_test, axis = -1) / ((np.sqrt(np.sum(x_train**2, axis = -1))) *(np.sqrt(np.sum(x_test**2, axis = -1))))\n",
        "\n",
        "class KNN:\n",
        "  # constructor\n",
        "  def __init__(self, K = 1, dist_fn = euclidean):\n",
        "    self.dist_fn = dist_fn\n",
        "    self.K = K\n",
        "\n",
        "  def fit(self, x_train, y_train):\n",
        "    # stores the training data, since KNN is a lazy learner\n",
        "    self.x_train = x_train\n",
        "    self.y_train = y_train\n",
        "\n",
        "    # the number of classes\n",
        "    self.class_count = len(set(y_train))\n",
        "    return self\n",
        "\n",
        "  def predict(self, x_test):\n",
        "    # uses the stored training data and x_test (test data passed as input)\n",
        "\n",
        "    # the number of instances in the testing data\n",
        "    instance_count = x_test.shape[0]\n",
        "\n",
        "    # an array of the distances between the training data points and the testing\n",
        "    # data points\n",
        "    distances_arr = self.dist_fn(self.x_train[None, :, :], x_test[:, None, :])\n",
        "    \n",
        "    # initializes an array full of zeros for the k-nearest neighbours\n",
        "    knn_arr = np.zeros((instance_count, self.K), dtype = int)\n",
        "    # initializes an array full of zeros for the class probabilities\n",
        "    class_prob = np.zeros((instance_count, self.class_count))\n",
        "\n",
        "    # iterates through each instance in the testing data\n",
        "    for instance in range(instance_count):\n",
        "      # the i-th index is an array with the k-nearest neighbours in x_train to\n",
        "      # data point i in x_test\n",
        "      knn_arr[instance, :] = np.argsort(distances_arr[instance])[:self.K]\n",
        "      \n",
        "      # the i-th index is an array counting the occurrence of each\n",
        "      # class type for data point i in x_test where the j-th index of the \n",
        "      # sub-array represents the number of neighbours in x_train of class j\n",
        "      class_prob[instance, :] = np.bincount(self.y_train[knn_arr[instance,:]], minlength = self.class_count)\n",
        "      #print(self.y_train[knn_arr[instance, :]].dtype)\n",
        "\n",
        "    # divides all probabilities by the number of neighbours to look for\n",
        "    class_prob /= self.K\n",
        "\n",
        "    return class_prob, knn_arr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "vFWDVUnTl3gR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node"
      ],
      "metadata": {
        "id": "vfuiSC0ZoZbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MTzVXa7EGN9Z"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "  def __init__(self, instance_indices, parent):\n",
        "\n",
        "    # the indices of the instances (in the data) within this region of the DT\n",
        "    self.instance_indices = instance_indices\n",
        "    self.left = None\n",
        "    self.right = None\n",
        "    self.split_feature = None\n",
        "    self.split_val = None\n",
        "\n",
        "    # if the node has a parent\n",
        "    if parent:\n",
        "      self.depth = parent.depth + 1\n",
        "      self.class_count = parent.class_count\n",
        "      \n",
        "      # pointer to original data\n",
        "      self.data = parent.data\n",
        "      self.labels = parent.labels\n",
        "      class_prob = np.bincount(self.labels[instance_indices], minlength = self.class_count)\n",
        "      self.class_prob = class_prob / np.sum(class_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Greedy Split"
      ],
      "metadata": {
        "id": "tL4lpMT8obue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7GhZiho7IEuM"
      },
      "outputs": [],
      "source": [
        "def greedy_split(node, cost_fn):\n",
        "  # if the split cannot be made, returns infinity\n",
        "  best_cost = np.inf\n",
        "  best_feature, best_value = None, None\n",
        "  instance_count, feature_count = node.data.shape\n",
        "  best_split = None\n",
        "\n",
        "  # sorts the data within each column then saves boundary values in test_splits\n",
        "  sorted_data = np.sort(node.data[node.instance_indices], axis = 0)\n",
        "  test_splits = (sorted_data[1:] + sorted_data[:-1]) / 2\n",
        "\n",
        "  for feature in range(feature_count):\n",
        "    feature_data = node.data[node.instance_indices, feature]\n",
        "\n",
        "    if(len(set(feature_data)) == 2):\n",
        "      left_indices = node.instance_indices[feature_data == 0]\n",
        "      right_indices = node.instance_indices[feature_data == 1]\n",
        "\n",
        "    else:\n",
        "      for split in test_splits[:, feature]:\n",
        "        left_indices = node.instance_indices[feature_data <= split]\n",
        "        right_indices = node.instance_indices[feature_data > split]\n",
        "\n",
        "        if (len(left_indices) == 0) or (len(right_indices) == 0):\n",
        "          continue\n",
        "\n",
        "      left_cost = cost_fn(node.labels[left_indices])\n",
        "      right_cost = cost_fn(node.labels[right_indices])\n",
        "\n",
        "      left_count, right_count = left_indices.shape[0], right_indices.shape[0]\n",
        "      cost = ((left_count * left_cost) + (right_count * right_cost)) / instance_count\n",
        "\n",
        "      if cost < best_cost:\n",
        "        best_cost = cost\n",
        "        best_feature = feature\n",
        "        best_split = split\n",
        "\n",
        "  return best_cost, best_feature, best_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cost Functions"
      ],
      "metadata": {
        "id": "IUFBqJ_voeHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KA60w5IZMbum"
      },
      "outputs": [],
      "source": [
        "### cost functions\n",
        "\n",
        "def misclassification_cost(labels):\n",
        "  most_frequent_label = np.argmax(labels)\n",
        "  cost = sum(1 for label in labels if label != most_frequent_label)\n",
        "  return cost\n",
        "\n",
        "def entropy_cost(labels):\n",
        "  cost = 0\n",
        "  unique_labels = set(labels)\n",
        "  label_count = len(labels)\n",
        "\n",
        "  for label in unique_labels:\n",
        "    cur_labels = sum(1 for label in unique_labels)\n",
        "    ratio = cur_labels / label_count\n",
        "    cost += ratio * np.log2(ratio)\n",
        "\n",
        "  cost *= -1\n",
        "  return cost\n",
        "\n",
        "def gini_cost(labels):\n",
        "  cost = 0\n",
        "  unique_labels = set(labels)\n",
        "  label_count = len(labels)\n",
        "\n",
        "  for label in unique_labels:\n",
        "    cur_labels = sum(1 for label in unique_labels)\n",
        "    ratio = cur_labels / label_count\n",
        "    cost += np.square(ratio)\n",
        "\n",
        "  cost = 1 - cost\n",
        "  return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DT model implementations"
      ],
      "metadata": {
        "id": "DQC1h0GDogf2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LF9f307pWx0P"
      },
      "outputs": [],
      "source": [
        "### the tree stops splitting if\n",
        "### 1) there are not enough points under the current node (min_instances)\n",
        "### 2) maximum depth reached (max_depth)\n",
        "### 3) decrease in cost is negligible\n",
        "\n",
        "class DT:\n",
        "  def __init__(self, class_count = None, max_depth = 3, cost_fn = entropy_cost, min_instances = 1):\n",
        "    self.root = None\n",
        "    self.max_depth = max_depth\n",
        "    self.cost_fn = cost_fn\n",
        "    self.class_count = class_count\n",
        "    self.min_instances = min_instances\n",
        "\n",
        "  def fit(self, data, labels):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "\n",
        "    if self.class_count is None:\n",
        "      self.class_count = len(set(labels))\n",
        "\n",
        "    # root\n",
        "    self.root = Node(np.arange(data.shape[0]), None)\n",
        "    self.root.data = data\n",
        "    self.root.labels = labels\n",
        "    self.root.class_count = self.class_count\n",
        "    self.root.depth = 0\n",
        "\n",
        "    # builds the rest of the tree\n",
        "    self.fit_recursive(self.root)\n",
        "\n",
        "    return self\n",
        "\n",
        "  def fit_recursive(self, node):\n",
        "    max_depth_reached = node.depth == self.max_depth\n",
        "    insufficient_instances = len(node.instance_indices) <= self.min_instances\n",
        "\n",
        "    # if the maximum depth was reached\n",
        "    if max_depth_reached or insufficient_instances:\n",
        "      return\n",
        "\n",
        "    cost, split_feature, split_value = greedy_split(node, self.cost_fn)\n",
        "\n",
        "    # it's not possible to split\n",
        "    if np.isinf(cost):\n",
        "      return\n",
        "\n",
        "    left_split_indices = node.data[node.instance_indices, split_feature] <= split_value\n",
        "\n",
        "    node.split_feature = split_feature\n",
        "    node.split_value = split_value\n",
        "\n",
        "    # new nodes\n",
        "    new_left = Node(node.instance_indices[left_split_indices], node)\n",
        "    new_right = Node(node.instance_indices[np.logical_not(left_split_indices)], node)\n",
        "\n",
        "    # recursive call\n",
        "    self.fit_recursive(new_left)\n",
        "    self.fit_recursive(new_right)\n",
        "\n",
        "    node.left = new_left\n",
        "    node.right = new_right\n",
        "\n",
        "  def predict(self, x_test):\n",
        "    # initializing empty array\n",
        "    class_probs = np.zeros((x_test.shape[0], self.class_count))\n",
        "\n",
        "    for instance_num, instance_features in enumerate(x_test):\n",
        "      node = self.root\n",
        "      \n",
        "      while node.left:\n",
        "        if instance_features[node.split_feature] <= node.split_value:\n",
        "          node = node.left\n",
        "        else:\n",
        "          node = node.right\n",
        "\n",
        "      # while loop terminates when you reach a leaf of the tree\n",
        "      # the class probability of that node is taken for prediction\n",
        "      class_probs[instance_num, :] = node.class_prob\n",
        "\n",
        "    return class_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Trees"
      ],
      "metadata": {
        "id": "A99WqN6WlACV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to build the decision tree class we need to implement various components:\n",
        "\n",
        "\n",
        "*   Nodes to describe the structure\n",
        "*   Cost function to evaluate a split and choose the best feature\n",
        "*   Greedy test (can be heuristic) to do the selection"
      ],
      "metadata": {
        "id": "y1eKC759lGIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node:"
      ],
      "metadata": {
        "id": "dhLtaaCrnYnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##This implementation is derrived from code found in DecisionTree.ipynb from the class's GitHub \n",
        "\n",
        "class Node:\n",
        "    def __init__(self, data_indices, parent):\n",
        "        self.data_indices = data_indices                    #stores the indices of the data in the region of this node\n",
        "        self.left = None                                    #stores the left child of this node \n",
        "        self.right = None                                   #stores the right child of this node\n",
        "\n",
        "        #Splitting parameters\n",
        "        self.split_feature = None                           #the feature being split at this node (data[f])\n",
        "        self.split_value = None                             #the value that splits the data at this node. (data[f] <= value)\n",
        "\n",
        "        #data passed from the parent\n",
        "        if parent:\n",
        "            self.depth = parent.depth + 1                   #this node's depth is 1 more than the parent's \n",
        "            self.num_classes = parent.num_classes           #copies the num classes from the parent which will be the same for all nodes\n",
        "            self.data = parent.data                         #copies the data from the parent \n",
        "            self.labels = parent.labels                     #copies the labels from the parent\n",
        "            class_prob = np.bincount(self.labels[data_indices], minlength=self.num_classes) #this is counting frequency of different labels in the region defined by this node\n",
        "            self.class_prob = class_prob / np.sum(class_prob)  #stores the class probability for the node\n",
        "            #note that we'll use the class probabilites of the leaf nodes for making predictions after the tree is built"
      ],
      "metadata": {
        "id": "R-uBBVbhk_QW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost functions"
      ],
      "metadata": {
        "id": "tvUlnzwnqKgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#several different cost functions are implemented here \n",
        "\n",
        "#misclassification\n",
        "def cost_misclassification(labels):\n",
        "  #find the highest count (which will be how they are all labelled) \n",
        "  correct_Perc = np.max(np.bincount(labels))/len(labels) #find which label has the highest count then divide by the total number of samples in labels to find the frequency of correctly classified\n",
        "  return 1- correct_Perc # return the percent of missclassified\n",
        "\n",
        "#entropy of the labels by computing the class probabilities\n",
        "def cost_entropy(labels):\n",
        "  class_probs = np.bincount(labels) / len(labels)      #calculate class probabilities by dividing the # of each class by the total number\n",
        "  class_probs = class_probs[class_probs > 0]              #this steps is remove 0 probabilities for removing numerical issues while computing log\n",
        "  return -np.sum(class_probs * np.log2(class_probs))       #expression for entropy -\\sigma p(x)log[p(x)]\n",
        "\n",
        "#computes the gini index cost\n",
        "def cost_gini_index(labels):\n",
        "    class_probs = np.bincount(labels) / len(labels)      #calculate class probabilities by dividing the # of each class by the total number\n",
        "    return 1 - np.sum(np.square(class_probs))               #expression for gini index 1-\\sigma p(x)^2"
      ],
      "metadata": {
        "id": "7kZJ4ga1qVtR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Greedy Test"
      ],
      "metadata": {
        "id": "ecRe9mSy8XS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_test(node, cost_fn):\n",
        "    #initialize the best parameter values (at the start there aren't any)\n",
        "    min_cost = np.inf \n",
        "    best_feature, best_value = None, None\n",
        "\n",
        "    num_instances, num_features = node.data.shape #the number of instances is equal to the number of rows in the data, #features is equal to the # columns\n",
        "\n",
        "    #sort the features to get the test value candidates by taking the average of consecutive sorted feature values \n",
        "    data_sorted = np.sort(node.data[node.data_indices],axis=0)\n",
        "    test_candidates = (data_sorted[1:] + data_sorted[:-1]) / 2. #gives each combination of left and right segments of the sorted data\n",
        "    #ex: i = [1,2,3,4,5], test_cand = [1.5, 2.5, 3.5, 4.5]\n",
        "\n",
        "    for d in range(num_features):\n",
        "      #stores the data corresponding to the d-th feature\n",
        "      data_d = node.data[node.data_indices, d]\n",
        "\n",
        "      for val in test_candidates[:, d]: #for each value of a given feature\n",
        "        #Split the indices using the test value of f-th feature\n",
        "            left_indices = node.data_indices[data_d <= val]\n",
        "            right_indices = node.data_indices[data_d > val]\n",
        "\n",
        "            #we can't have a split where a child has zero element (it would pretty much result in the same node again)\n",
        "            #if this is true over all the test features and their test values  then the function returns the best cost as infinity\n",
        "            if len(left_indices) == 0 or len(right_indices) == 0:                \n",
        "                continue\n",
        "\n",
        "            left_cost = cost_fn(node.labels[left_indices]) #calculate cost for the left side\n",
        "            right_cost = cost_fn(node.labels[right_indices]) #calculate cost for the right side\n",
        "\n",
        "\n",
        "            num_left, num_right = left_indices.shape[0], right_indices.shape[0] # weighted cost = cost * numElements / totalnumElements\n",
        "            #get the combined cost using the weighted sum of left and right cost for the cuurent test value and feature\n",
        "            cost = (num_left * left_cost + num_right * right_cost)/num_instances \n",
        "            \n",
        "            #update only when a lower cost is encountered\n",
        "            if cost < min_cost:\n",
        "                min_cost = cost\n",
        "                best_feature = d\n",
        "                best_value = val\n",
        "    return min_cost, best_feature, best_value"
      ],
      "metadata": {
        "id": "Orql5Bud8Zs5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree class. We are now ready to implement the fit and predict functions"
      ],
      "metadata": {
        "id": "RWE4NRXoXupP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, num_classes=None, max_depth=3, cost_fn=cost_misclassification, min_leaf_instances=1):\n",
        "      self.max_depth = max_depth      #maximum dept for termination \n",
        "      self.root = None                #stores the root of the decision tree \n",
        "      self.cost_fn = cost_fn          #stores the cost function of the decision tree \n",
        "      self.num_classes = num_classes  #stores the total number of classes\n",
        "      self.min_leaf_instances = min_leaf_instances  #minimum number of instances in a leaf for termination\n",
        "\n",
        "\n",
        "    def fit(self, data, labels):\n",
        "      self.data = data\n",
        "      self.labels = labels\n",
        "      if self.num_classes is None:\n",
        "        self.num_classes = np.max(labels) + 1 #assumes the labels start at 0\n",
        "\n",
        "        #below are initialization of the root of the decision tree\n",
        "      self.root = Node(np.arange(data.shape[0]), None) #root should include all data indices and should not have a parent\n",
        "      self.root.data = data\n",
        "      self.root.labels = labels\n",
        "      self.root.num_classes = self.num_classes\n",
        "      self.root.depth = 0\n",
        "      #to recursively build the rest of the tree\n",
        "      self._fit_tree(self.root)\n",
        "      return self\n",
        "\n",
        "\n",
        "    def _fit_tree(self, node):\n",
        "\n",
        "      #This gives the condition for termination of the recursion resulting in a leaf node\n",
        "      if node.depth == self.max_depth or len(node.data_indices) <= self.min_leaf_instances:\n",
        "        return\n",
        "        #greedily select the best test by minimizing the cost\n",
        "      cost, split_feature, split_value = greedy_test(node, self.cost_fn)\n",
        "\n",
        "          #if the cost returned is infinity it means that it is not possible to split the node and hence terminate\n",
        "      if np.isinf(cost):\n",
        "        return\n",
        "\n",
        "          #to get a boolean array suggesting which data indices corresponding to this node are in the left of the split\n",
        "      test = node.data[node.data_indices,split_feature] <= split_value\n",
        "          #store the split feature and value of the node\n",
        "      node.split_feature = split_feature\n",
        "      node.split_value = split_value\n",
        "          #define new nodes which are going to be the left and right child of the present node\n",
        "      left = Node(node.data_indices[test], node)\n",
        "      right = Node(node.data_indices[np.logical_not(test)], node)\n",
        "          #recursive call to the _fit_tree()\n",
        "      self._fit_tree(left)\n",
        "      self._fit_tree(right)\n",
        "          #assign the left and right child to present child    \n",
        "      node.left = left\n",
        "      node.right = right\n",
        "            \n",
        "    def predict(self, data_test):\n",
        "      pass"
      ],
      "metadata": {
        "id": "wf7qtkHMX5UR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we have to define the predict function"
      ],
      "metadata": {
        "id": "HApa10mQa941"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(self, data_test):\n",
        "\n",
        "    class_probs = np.zeros((data_test.shape[0], self.num_classes))\n",
        "    for n, x in enumerate(data_test):\n",
        "        node = self.root\n",
        "        #loop along the dept of the tree looking region where the present data sample fall in based on the split feature and value\n",
        "        while node.left:\n",
        "            if x[node.split_feature] <= node.split_value:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        #the loop terminates when you reach a leaf of the tree and the class probability of that node is taken for prediction\n",
        "        class_probs[n,:] = node.class_prob\n",
        "    return class_probs\n",
        "\n",
        "DecisionTree.predict = predict"
      ],
      "metadata": {
        "id": "Tjb-bmLca8yf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running experiments"
      ],
      "metadata": {
        "id": "IlELJSq3nWUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN experiments"
      ],
      "metadata": {
        "id": "SNenEnbonsLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline accuracy test"
      ],
      "metadata": {
        "id": "O-Hcvjovo1K9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "E81-AwpM10sb",
        "outputId": "87dd9458-0657-468c-fc5d-6c5279b28aee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-81155be1ecac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhep_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0msimpleTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmess_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-81155be1ecac>\u001b[0m in \u001b[0;36msimpleTest\u001b[0;34m(x_train, y_train, x_test, y_test, k)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# outputs an array of the most likely class labels for each instance in x_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mclass_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_class_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# finds the training accuracy of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \"\"\"\n\u001b[0;32m-> 1195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
          ]
        }
      ],
      "source": [
        "### running KNN to find test accuracy and training accuracy\n",
        "def simpleTest(x_train, y_train, x_test, y_test, k):\n",
        "  # creates a new KNN model\n",
        "  knn_model = KNN(K = k)\n",
        "  knn_model = knn_model.fit(x_train, y_train)\n",
        "  # fits the model to the training data, then tests the model on the test\n",
        "  # data for K = 3\n",
        "  class_prob, knn_arr = knn_model.predict(x_test)\n",
        "  tr_class_prob, _ = knn_model.predict(x_train)\n",
        "\n",
        "  # outputs an array of the most likely class labels for each instance in x_test\n",
        "  class_pred = np.argmax(class_prob, axis = -1)\n",
        "  train_pred = np.argmax(tr_class_prob, axis = -1)\n",
        "  # finds the training accuracy of the model\n",
        "  test_accuracy = evaluate_acc(y_test, class_pred)\n",
        "  train_accuracy = evaluate_acc(y_train, train_pred)\n",
        "  # creates boolean arrays to represent correct and incorrect predictions\n",
        "  correct_pred = class_pred == y_test\n",
        "  incorrect_pred = np.logical_not(correct_pred)\n",
        "\n",
        "  print(\"K = \" + str(k))\n",
        "  print(\"The accuracy of the model on the training data is: \" + str(round((train_accuracy * 100), 2)) + \"%\")\n",
        "  print(\"The accuracy of the model on the test data is: \" + str(round((test_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "x_train, y_train, x_test, y_test = train_test_split(hep_df)\n",
        "simpleTest(x_train, y_train, x_test, y_test, k=3)\n",
        "\n",
        "x_train, y_train, x_test, y_test = train_test_split(mess_df)\n",
        "simpleTest(x_train, y_train, x_test, y_test, k=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=1) # n_neighbors=5 (default)\n",
        "fit = knn.fit(x_train, y_train)\n",
        "pred_y = fit.predict(x_test)\n",
        "evaluate_acc(y_test, pred_y)"
      ],
      "metadata": {
        "id": "_jGB49-CyXPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cEsR4vrQXo4"
      },
      "outputs": [],
      "source": [
        "### running KNN on mess_df data\n",
        "\n",
        "x_train, y_train, x_test, y_test = train_test_split(mess_df)\n",
        "\n",
        "knn_model = KNN(K = 3)\n",
        "\n",
        "# fits the model to the training data, then tests the model on the test\n",
        "# data for K = 3\n",
        "class_prob, knn_arr = knn_model.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "# outputs an array of the most liekly class label for each instance in x_test\n",
        "class_pred = np.argmax(class_prob, axis = -1)\n",
        "\n",
        "# finds the accuracy of the model\n",
        "accuracy = evaluate_acc(y_test, class_pred)\n",
        "\n",
        "# creates boolean arrays to represent correct and incorrect predictions\n",
        "correct_pred = class_pred == y_test\n",
        "incorrect_pred = np.logical_not(correct_pred)\n",
        "\n",
        "print(\"The accuracy of the model is: \" + str(round((accuracy * 100), 2)) + \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acurracy test with removed low correlation features"
      ],
      "metadata": {
        "id": "VGTmIRwao9gV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggyVjkbpFp0L"
      },
      "outputs": [],
      "source": [
        "### running KNN on hep_df data for top 2 features\n",
        "\n",
        "hep_cut_df = normalize_df(hep_df[['CLASS', 'ALBUMIN', 'BILIRUBIN']])\n",
        "\n",
        "# splits the data\n",
        "x_train, y_train, x_test, y_test = train_test_split(hep_cut_df)\n",
        "\n",
        "# creates a new KNN model\n",
        "knn_model = KNN(K = 3)\n",
        "\n",
        "# fits the model to the training data, then tests the model on the test\n",
        "# data for K = 3\n",
        "class_prob, knn_arr = knn_model.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "# outputs an array of the most likely class labels for each instance in x_test\n",
        "class_pred = np.argmax(class_prob, axis = -1)\n",
        "\n",
        "# finds the accuracy of the model\n",
        "accuracy = evaluate_acc(y_test, class_pred)\n",
        "\n",
        "print(\"The accuracy of the model is: \" + str(round((accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "# creates boolean arrays to represent correct and incorrect predictions\n",
        "correct_pred = class_pred == y_test\n",
        "incorrect_pred = np.logical_not(correct_pred)\n",
        "\n",
        "plt.scatter(x_train[:, 0], x_train[:, 1], c = y_train, marker = 'o', alpha = 0.2, label = 'train')\n",
        "plt.scatter(x_test[correct_pred, 0], x_test[correct_pred, 1], marker = '.', c = class_pred[correct_pred], label = 'correct')\n",
        "plt.scatter(x_test[incorrect_pred, 0], x_test[incorrect_pred, 1], marker = 'x', c = class_pred[incorrect_pred], label = 'misclassified')\n",
        "\n",
        "for i in range(x_test.shape[0]):\n",
        "  for k in range(knn_model.K):\n",
        "\n",
        "    hor = x_test[i, 0], x_train[knn_arr[i, k], 0]\n",
        "    ver = x_test[i, 1], x_train[knn_arr[i, k], 1]\n",
        "\n",
        "    plt.plot(hor, ver, 'k-', alpha = 0.1)\n",
        "\n",
        "plt.xlabel('Albumin')\n",
        "plt.ylabel('Bilirubin')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skthqvpEbkb1"
      },
      "outputs": [],
      "source": [
        "### running KNN on mess_df data for top 2 correlated features\n",
        "\n",
        "mess_cut_df = mess_df[['Class', '2', '9']]\n",
        "\n",
        "x_train, y_train, x_test, y_test = train_test_split(mess_cut_df)\n",
        "\n",
        "knn_model = KNN(K = 3)\n",
        "\n",
        "# fits the model to the training data, then tests the model on the test\n",
        "# data for K = 3\n",
        "class_prob, knn_arr = knn_model.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "# outputs an array of the most liekly class label for each instance in x_test\n",
        "class_pred = np.argmax(class_prob, axis = -1)\n",
        "\n",
        "# finds the accuracy of the model\n",
        "accuracy = evaluate_acc(y_test, class_pred)\n",
        "\n",
        "# creates boolean arrays to represent correct and incorrect predictions\n",
        "correct_pred = class_pred == y_test\n",
        "incorrect_pred = np.logical_not(correct_pred)\n",
        "\n",
        "print(\"The accuracy of the model is: \" + str(round((accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "plt.scatter(x_train[:, 0], x_train[:, 1], c = y_train, marker = 'o', alpha = 0.2, label = 'train')\n",
        "plt.scatter(x_test[correct_pred, 0], x_test[correct_pred, 1], marker = '.', c = class_pred[correct_pred], label = 'correct')\n",
        "plt.scatter(x_test[incorrect_pred, 0], x_test[incorrect_pred, 1], marker = 'x', c = class_pred[incorrect_pred], label = 'misclassified')\n",
        "\n",
        "for i in range(x_test.shape[0]):\n",
        "  for k in range(knn_model.K):\n",
        "\n",
        "    hor = x_test[i, 0], x_train[knn_arr[i, k], 0]\n",
        "    ver = x_test[i, 1], x_train[knn_arr[i, k], 1]\n",
        "\n",
        "    plt.plot(hor, ver, 'k-', alpha = 0.1)\n",
        "\n",
        "plt.xlabel('2')\n",
        "plt.ylabel('9')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing different values for K"
      ],
      "metadata": {
        "id": "l2YQZ_f4rOr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We must first create a validation set"
      ],
      "metadata": {
        "id": "WxASYYY7sQSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def testDifK(x, y, fileName):\n",
        "  #now we can divide the data into 3 sections: training, validation, testing\n",
        "\n",
        "  x_tr, x_tst, y_tr, y_tst =   train_test_split(x, y, test_size=0.2, random_state=11)\n",
        "  x_tr, x_valid, y_tr, y_valid = train_test_split(x_tr, y_tr, test_size=0.2, random_state=11)\n",
        "  \n",
        "\n",
        "  ### choise of max depth\n",
        "  model_choices=[]\n",
        "  train_acc = []\n",
        "  valid_acc = []\n",
        "\n",
        "  n_train = y_tr.shape[0]\n",
        "  n_valid = y_valid.shape[0]\n",
        "\n",
        "  for k in range(1, 15):\n",
        "      knn = KNN(K=k) # create a knn object (OOP)\n",
        "\n",
        "      y_train_tr_prob,_ = knn.fit(x_tr, y_tr).predict(x_tr)\n",
        "      y_train_tr_pred = np.argmax(y_train_tr_prob, axis=-1)\n",
        "      acc_tr = np.sum(y_train_tr_pred == y_tr)/n_train\n",
        "\n",
        "      y_train_va_prob,_ = knn.fit(x_tr, y_tr).predict(x_valid)\n",
        "      y_train_va_pred = np.argmax(y_train_va_prob, axis=-1)\n",
        "      acc_va = np.sum(y_train_va_pred == y_valid)/n_valid\n",
        "\n",
        "      model_choices.append(k)\n",
        "      train_acc.append(acc_tr)\n",
        "      valid_acc.append(acc_va)\n",
        "\n",
        "  # use the best K to predict test data\n",
        "  best_k = model_choices[valid_acc.index(max(valid_acc))]\n",
        "  knn = KNN(K=best_k)\n",
        "  y_test_prob,_ = knn.fit(x_tr, y_tr).predict(x_tst)\n",
        "\n",
        " \n",
        "\n",
        "  y_test_pred = np.argmax(y_test_prob, axis=-1)\n",
        " \n",
        "  test_accuracy = np.sum(y_test_pred == y_tst)/y_tst.shape[0]\n",
        "  print(f'best depth = {best_k}, test accuracy = {test_accuracy}')\n",
        "\n",
        "  plt.plot(model_choices, train_acc, marker='d', color='black', label='training')\n",
        "  plt.plot(model_choices, valid_acc, marker='o', color='blue', label='validation')\n",
        "  plt.plot(best_k, test_accuracy, marker='*', color='red', label='testing')\n",
        "  plt.xlabel(\"K\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.savefig(fileName,dpi=300,bbox_inches='tight')"
      ],
      "metadata": {
        "id": "fK2z-VobqV2i"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing on Hepatitis data"
      ],
      "metadata": {
        "id": "-O7xMSfgtUps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(1234)\n",
        "x = hep_df.iloc[:, :-1].to_numpy()\n",
        "y = np.ravel((hep_df.iloc[:, -1:]).to_numpy())\n",
        "testDifK(x, y, 'hep_knn_chooseK.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "D2qHfC8MtP24",
        "outputId": "db1638a6-4ecb-4390-eea1-d736f43fa294"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best depth = 1, test accuracy = 0.7241379310344828\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing on Messiador feature data"
      ],
      "metadata": {
        "id": "kcl9ugXutZMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(1234)\n",
        "x = mess_df.iloc[:, :-1].to_numpy()\n",
        "y = np.ravel((mess_df.iloc[:, -1:]).to_numpy())\n",
        "testDifK(x, y, 'mess_knn_chooseK.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "V8mRA4gMtczR",
        "outputId": "6df0c997-af51-463a-81bf-1285f41e88a7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best depth = 12, test accuracy = 0.6804123711340206\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxVdfrA8c8XJBHUJBXXBMYsBdxwyXLUS9lkUFbmkuVkqW1TVlNZWtNeo79snRqdMpmmdDKzMh1MLUfLPXErwEZNc0sBF1xAFOT5/XEA2blw7+UA93m/XufFXc4957m3PM853+/3PF8jIiillPJePnYHoJRSyl6aCJRSystpIlBKKS+niUAppbycJgKllPJy9ewOoLKaNWsmoaGhdoehlFK1ysaNGw+LSPPS3qt1iSA0NJSEhAS7w1BKqVrFGLOnrPe0aUgppbycJgKllPJymgiUUsrL1bo+AqVU3ZKdnc3+/fvJysqyO5Q6wd/fn7Zt2+Ln5+f0Z7wmESQlJTFixAg+/fRTIiIi7A5HKZVn//79NGrUiNDQUIwxdodTq4kIR44cYf/+/YSFhTn9OY81DRlj4owxqcaYxDLeN8aYvxljdhpjfjTGRHkqloyMDGJiYkhOTiY2NpaMjAxP7UopVUlZWVk0bdpUk4AbGGNo2rRppa+uPNlH8CEwqJz3rwM65C33ANM9FciYMWNITU1FREhJSWHs2LGe2pVSqgo0CbhPVX5LjyUCEfkeOFrOKjcCH4llHdDEGNPK3XHExcURHx9fkCGzsrJYuHAhcXFx7t6VUkrVSnaOGmoD7Cv0fH/eayUYY+4xxiQYYxLS0tIqtZNJkyaVaArKzMxk0qRJlQxXKVVTJCUlERkZSVJSksvbSk9PZ9q0aZX+XExMDOnp6eWu8+yzz/Ltt99WNbRqUyuGj4rI+yLSU0R6Nm9e6h3SZZo8eTKBgYFFXgsICGDKlCnuDFEpVU3c3edXViLIyckp93OLFi2iSZMm5a7z4osvMnDgQJfiqw52JoIDwMWFnrfNe82txowZQ2xsLP7+/gD4+Phwww03cNddd7l7V0qpauDuPr+JEyfyyy+/0K1bN3r16kW/fv0YPHgw4eHhANx000306NGDiIgI3n///YLPhYaGcvjwYX799Vc6derE3XffTUREBH/4wx84ffo0AHfeeSfz5s0rWP+5554jKiqKzp078/PPPwOQlpbGNddcQ0REBOPGjSMkJITDhw+79J0qy87howuAB40xc4DLgeMictATO4qLiyM8PJy9e/dijOGDDz7wxG6UUi565JFH2LJlS5nvHzx4kJ07d5KbmwtYfX6fffYZmzdvplWr0rsYu3XrxltvvVXmNqdMmUJiYiJbtmxhxYoVxMbGkpiYWDD8Mi4ujosuuojTp0/Tq1cvbrnlFpo2bVpkGzt27OCTTz5hxowZDB8+nM8//5xRo0aV2FezZs3YtGkT06ZN47XXXuODDz7ghRde4KqrrmLSpEksXryYmTNnVvg7uZsnh49+AqwFLjPG7DfGjDXG3GeMuS9vlUXALmAnMAP4k6diCQwMZNGiRbRq1Ypz586RkpLiqV0ppTxo9+7dBUkgX25uLrt373bbPnr37l1kDP7f/vY3unbtSp8+fdi3bx87duwo8ZmwsDC6desGQI8ePfj1119L3faQIUNKrLNq1SpuvfVWAAYNGkRQUJDbvouzPHZFICIjK3hfgAc8tf/iIiIiWLZsGeHh4Sxfvpz27dtX166VUk4q78wdrLPzhx56qEi/QEBAAO+++67bmnsL9ymuWLGCb7/9lrVr1xIQEIDD4Sh1jH79+vULHvv6+hY0DZW1nq+vb4V9ENWpVnQWu0vHjh1p0aIFK1assDsUpVQVFO/z8/f3d7nPr1GjRpw8ebLU944fP05QUBABAQH8/PPPrFu3rsr7KUvfvn2ZO3cuAEuXLuXYsWNu30dFvCoRGGNwOBwsX74c64JEKVXbxMXFERwcjDGGFi1auNym3rRpU/r27UtkZCQTJkwo8t6gQYPIycmhU6dOTJw4kT59+ri0r9I899xzLF26lMjISD777DNatmxJo0aN3L6fcolIrVp69OghrvjHP/4hgGzfvt2l7Sil3CM5ObnSn0lMTJSIiAhJTEz0QETVKysrS7Kzs0VEZM2aNdK1a1eXt1nabwokSBnHVa8pOpfP4XAAsHz5cjp06GBvMEqpKomIiCAxsdQyZrXO3r17GT58OLm5uVxwwQXMmDGj2mPwukRw6aWX0qpVK1asWME999xjdzhKKS/XoUMHNm/ebGsMXtVHANpPoJRSxXldIgCIjo7m0KFDbN++3e5QlFLKdl6ZCAr3EyillLfzykRwySWX0KZNG72fQCml8NJEYIwhOjqaFStWaD+BUqpSGjZsCMBvv/3G0KFDS13H4XCQkJBQ7nbeeustMjMzC547U9baU7wyEYD1HyolJaWgAqBSqnaYPRtCQ8HHx/o7e7Y9cbRu3bqgsmhVFE8EzpS19hSvTQTR0dGA9hMoVZvMng333AN79oCI9feee1xLBhMnTuTvf/97wfPnn3+el19+mauvvrqgZPRXX31V4nO//vorkZGRAJw+fZpbb72VTp06cfPNNxepNXT//ffTs2dPIiIieO655wCrkN1vv/1GdHR0wbEov6w1wBtvvEFkZCSRkZEF9ZfKK3ftsrLuNKupi6t3FufLzc2Viy++WIYOHeqW7SmlqqbwXbAPPywyYEDZS/36IlYKKLrUr1/2Zx5+uPz9b9q0Sfr371/wvFOnTrJ37145fvy4iIikpaVJ+/btJTc3V0REAgMDRURk9+7dEhERISIir7/+utx1110iIrJ161bx9fWVDRs2iIjIkSNHREQkJydHBgwYIFu3bhURkZCQEElLSyvYb/7zhIQEiYyMlFOnTsnJkyclPDxcNm3aJLt37xZfX1/ZvHmziIgMGzZMPv744wp/03yUc2ex114RaD+BUrXPmTOVe90Z3bt3JzU1ld9++42tW7cSFBREy5Yteeqpp+jSpQsDBw7kwIED5Zav//777wvmH+jSpQtdunQpeG/u3LlERUXRvXt3kpKSSE5OLjeeVatWcfPNNxMYGEjDhg0ZMmQIK1euBJwvd11ZXndncWEOh4OPPvqoYP5TpZS9KqhCTWio1RxUXEgIuDIIcNiwYcybN49Dhw4xYsQIZs+eTVpaGhs3bsTPz4/Q0NBSy09XZPfu3bz22mts2LCBoKAg7rzzziptJ5+z5a4ry2uvCOB8P4EOI1WqdnjlFQgIKPpaQID1uitGjBjBnDlzmDdvHsOGDeP48eMEBwfj5+fH8uXL2VNa9imkf//+/Pvf/wYgMTGRH3/8EYATJ04QGBjIhRdeSEpKCl9//XXBZ8oqf92vXz/mz59PZmYmGRkZfPnll/Tr18+1L1gBr04EoaGhhISEaIexUrXE7bfD++9bVwDGWH/ff9963RURERGcPHmSNm3a0KpVK26//XYSEhLo3LkzH330ER07diz38/fffz+nTp2iU6dOPPvss/To0QOArl270r17dzp27Mhtt91G3759Cz5zzz33MGjQoIIT0nxRUVHceeed9O7dm8svv5xx48bRvXt3175gBUxtax/v2bOnVDQ+tzLuuusuFi5cSGpqKj4+Xp0XlbLFtm3b6NSpk91h1Cml/abGmI0i0rO09b3+yOdwODhy5EidKWmrlFKVpYkgr+6Q9hMopbyV1yeCkJAQwsLCtJ9AKeW1vD4RgDV66LvvviM3N9fuUJRSqtppIsBqHjp27FjBkC+llPImmgjQfgKllHfTRABcfPHFtG/fXvsJlPJC6enpTJs2rUqfrUmlpF2hiSBPdHQ033//PefOnbM7FKVURQ4ehAED4NAhlzflzkRgZylpV2giyONwOEhPT2fr1q12h6KUqshLL8GqVfDiiy5vauLEifzyyy9069aNCRMmMHXqVHr16kWXLl0KykZnZGQQGxtL165diYyM5NNPPy23lHR5JaM3bNhAly5dCvZXE+qceXXRucIK9xNERUXZG4xS3uqRR2DLlrLfX7kSCo/umz7dWnx8oKx6PN26lVvNbsqUKSQmJrJlyxaWLl3KvHnz+OGHHxARBg8ezPfff09aWhqtW7cmPj4egOPHj3PhhRfyxhtvsHz5cpo1a1Ziuzt27OCTTz5hxowZDB8+nM8//5xRo0Zx1113MWPGDK644gomTpzo1M/iaXpFkKdNmzZ06NBB+wmUqsl694bgYOvAD9bf4GC4/HK3bH7p0qUsXbqU7t27ExUVxc8//8yOHTvo3Lkz33zzDU8++SQrV67kwgsvrHBbpZWMTk9P5+TJk1xxxRUA3HbbbW6J21V6RVBIdHQ0c+bM4dy5c/j6+todjlLep6I61AD3329VmvP3h7Nn4ZZboIpt/MWJCJMmTeLee+8t8d6mTZtYtGgRf/nLX7j66qt59tlny92Wp0pGe4JeERTicDg4ceIEmzdvtjsUpVRZUlLgvvtg3Trrr4sdxoXLQV977bXExcVx6tQpAA4cOFAwaU1AQACjRo1iwoQJbNq0qcRnndGkSRMaNWrE+vXrAZgzZ45LsbuLXhEUUrifoGfPUov0KaXs9sUX5x8Xmmu4qpo2bUrfvn2JjIzkuuuu47bbbitoumnYsCGzZs1i586dTJgwAR8fH/z8/Jg+fTpwvpR069atnW5WnjlzJnfffTc+Pj4MGDDAqWYmT/P6MtTFdezYkfbt2xd0CimlPMvbylCfOnWKhg0bAlZH9cGDB3n77bfdug8tQ+2i6OhoVq5cSU5Ojt2hKKXqoPj4eLp160ZkZCQrV67kL3/5i90haSIozuFwcPLkyYI2QKWUcqcRI0awZcsWEhMTiY+Pp3nz5naHpImguPx+Ah1GqlT1qW1N1DVZVX5LTQTFtGjRgk6dOmkBOqWqib+/P0eOHNFk4AYiwpEjR/D396/U53TUUCmio6P517/+RXZ2Nn5+fnaHo1Sd1rZtW/bv309aWprdodQJ/v7+tG3btlKf8WgiMMYMAt4GfIEPRGRKsfdDgDigOXAUGCUi+z0ZkzMcDgfTpk1j48aN9OnTx+5wlKrT/Pz8CAsLszsMr+axpiFjjC/wd+A6IBwYaYwJL7baa8BHItIFeBGY7Kl4KmPAgAGA9hMopbyDJ/sIegM7RWSXiJwF5gA3FlsnHPhv3uPlpbxvi+DgYCIiIrSfQCnlFTyZCNoA+wo935/3WmFbgSF5j28GGhljmhbfkDHmHmNMgjEmobraEaOjo1m1ahVnz56tlv0ppZRd7B419DgwwBizGRgAHABKzAwjIu+LSE8R6VldY24dDgeZmZl48i5mpZSqCTyZCA4AFxd63jbvtQIi8puIDBGR7sDTea/ViHnetJ9AKeUtPJkINgAdjDFhxpgLgFuBBYVXMMY0M8bkxzAJawRRjdCsWTM6d+6s/QRKqTrPY4lARHKAB4ElwDZgrogkGWNeNMYMzlvNAfzPGLMdaAG84ql4qiI6OprVq1dz5swZu0NRSimP8WgfgYgsEpFLRaS9iLyS99qzIrIg7/E8EemQt844EalRR1yHw8Hp06fZsGGD3aEopZTH2N1ZXKMNGDAAY4z2Eyil6jRNBOW46KKL6NKli/YTKKXqNE0EFYiOjmbNmjXaT6CUqrM0EVTA4XCQlZVVMMeoUkrVNZoIKtC/f3/tJ1BK1WmaCCoQFBREt27dtJ9AKVVnaSJwQnR0NGvXriUrK8vuUJRSyu00ETjB4XBw5swZ1q5da3coSinldpoInNCvXz98fHy0eUgpVSdpInBCkyZN6N69u3YYK6XqJE0EToqOjmb9+vVkZmbaHYpSSrmVJgInORwOzp49q/0ESqk6RxOBk7SfQClVV2kicFLjxo3p0aOH9hMopeocTQSVEB0dzQ8//EBGRobdoSillNtoIqgEh8NBdnY2a9assTsUpZRyG00ElfD73/8eX19f7SdQStUpmggqoVGjRvTs2VP7CZRSdYomgkqKjo5mw4YNnDp1yu5QlFLKLTQRVJLD4SAnJ4fVq1fbHYpSSrmFJoJK6tu3L/Xq1dN+AqVUnaGJoJIaNmxIr169tJ9AKVVnaCKogujoaBISEjh58qTdoSillMs0EVSBw+Hg3LlzrFq1yu5QlFLKZZoIquDKK6/Ez8+v2voJkpKSiIyMJCkpqVr2p5TyLpoIqiAwMJDevXtXSz9BRkYGMTExJCcnExsbq+UtlFJuV2EiMMbcYIzRhFFMdHQ0Gzdu5MSJEx7dz5gxY0hNTUVESElJYezYsR7dn1LK+zhzgB8B7DDGvGqM6ejpgGoLh8NBbm4uK1eu9Ng+4uLi+M9//kNWVhYAWVlZLFy4kLi4OI/tUynlfSpMBCIyCugO/AJ8aIxZa4y5xxjTyOPR1WBXXnklF1xwgcf6CY4dO8b48eNLzIiWmZnJpEmTPLJPpZR3cqrJR0ROAPOAOUAr4GZgkzFmvAdjq9EaNGhAnz593N5PcPLkSV5++WXCwsLIzMzE19e3yPt+fn5MmTLFrftUSnk3Z/oIBhtjvgRWAH5AbxG5DugKPObZ8Go2h8PB5s2bSU9Pd3lbWVlZvPnmm7Rv355nnnkGh8PBjz/+yC233IK/vz8Avr6+ZGdna50jpZRbOXNFcAvwpoh0FpGpIpIKICKZgFf3XEZHR7vcT5Cdnc17773HJZdcwqOPPkrXrl1Zt24d8+fPp3PnzsTFxREcHIwxhrZt2xIbG8vDDz/M3Llz3fhNlFLezJlE8DzwQ/4TY0wDY0wogIgs80hUtUSfPn2oX79+lZqHzp07x6xZs+jYsSP33XcfISEhLF++nG+++YbLL7+8YL3AwEAWLVpEeHg48fHxfPbZZ/Tt25dRo0axbJlX//xKKTdxJhF8BuQWen4u7zWv5+/vzxVXXFGpDmMR4YsvvqBLly788Y9/pHHjxsTHx7Nq1SocDkepn4mIiCAxMZGIiAgaNGjAggULuOyyy7j55pvZvHmze76MUsprOZMI6onI2fwneY8v8FxItYvD4WDLli0cPXq03PVEhMWLF9OrVy9uueUWcnNzmTt3Lhs3biQmJgZjjNP7DAoKYvHixQQFBXHdddfxyy+/uPo1lFJezJlEkGaMGZz/xBhzI3DYcyHVLtHR0YhIuf0EK1euZMCAAVx33XUcOXKEDz/8kJ9++olhw4bh41O1e/XatGnDkiVLyM7O5tprryUlJaWqX0Ep5eWcOQrdBzxljNlrjNkHPAnc69mwao/LL78cf39/5s2bV6IeUEJCAoMGDaJ///7s3LmTv//97/zvf/9j9OjR1KtXz+V9d+zYkfj4eH777TdiYmK0GqpSqmpExKkFaAg0dHZ9Ty09evSQmmbAgAHi5+cnxhgJCQmRH374QYYMGSKAXHTRRTJ16lTJyMjw2P7/85//iK+vrwwcOFDOnDnjsf0opWovIEHKOK46dVpqjIkFIgD//LZsEXnRic8NAt4GfIEPRGRKsffbAf8CmuStM1FEFjmZw2qMw4cPk52dDcC+ffvo3bs3jRo14vnnn+fPf/4zjRs39uj+Y2NjmTlzJnfeeSejR49m9uzZVW5yUkp5nwoTgTHmH0AAEA18AAyl0HDScj7nC/wduAbYD2wwxiwQkeRCq/0FmCsi040x4cAiILSyX8JOcXFxRTprc3NzqVevHq+88grjx1ffjdejR4/m0KFDTJw4kRYtWvDmm29WqgNaKeW9nDltvFJE7gCOicgLwBXApU58rjewU0R2iTXSaA5wY7F1BMg/Xb4Q+M25sGuOSZMmFRSFy5eTk8PLL79c7bE88cQTPPLII7z99tu8+uqr1b5/pVTt5EwiyD/KZRpjWgPZWPWGKtIG2Ffo+f681wp7HhhljNmPdTVQ62oXTZ48mcDAwCKvBQQE2FIPyBjD66+/zsiRI5k4cSIffvhhtceglKp9nEkEC40xTYCpwCbgV+Dfbtr/SOBDEWkLxAAflzb3QV610wRjTEJaWpqbdu0eY8aMITY2tqAekL+/PzfccAN33XWXLfH4+Pjw4YcfMnDgQMaNG0d8fLwtcSilag9jdSaX8aZ1UO4jImvyntcH/EXkeIUbNuYK4HkRuTbv+SQAEZlcaJ0kYJCI7Mt7vitvf6llbbdnz56SkJDgzHerNhkZGYSHh7Nv3z7atWtHUlJSiauE6nby5Emio6NJTk7mv//9L3369LE1HqWUvYwxG0WkZ2nvlXtFICK5WB2++c/POJME8mwAOhhjwowxFwC3AguKrbMXuDovyE6AP1CzTvmdULwekN1JAKBRo0YsWrSINm3aEBsby7Zt2+wOSSlVQznTNLTMGHOLqeQQFBHJAR4ElgDbsEYHJRljXix0p/JjwN3GmK3AJ8CdUt4lSg1WuB5QTREcHMySJUvw8/Pj2muvZf/+/XaHpJSqgcptGgIwxpwEAoEcrI5jA4iIeHZwfBlqYtNQTbd582YGDBhAu3btWLlyJUFBQXaHpJSqZlVuGgIQkUYi4iMiF4hI47zntiQBVTXdu3dn/vz57Nixg8GDB3P69Gm7Q1JK1SDOzFDWv7SlOoJT7nPVVVfx8ccfs3r1akaOHElOTk617DcpKalEDSalVM3iTImJCYUe+2PdKLYRuMojESmPGT58OKmpqYwfP54//elPvPfeex69+zgjI4OYmBj27dtHbGxsjRhNpZQqyZmmoRsKLdcAkcAxz4emPOHBBx/k6aefZsaMGTz33HOA587a77jjDlJSUhARUlJSGDvWq2c2VarGqkot5P1AJ3cHoqrPSy+9xKFDh3jppZcICgrirbfecvqsXUQ4duwYBw8eLHfZs2cPZ88WzGdEVlYWCxcuJC4ujjFjxlTH11RKOcmZUUPvYNUEAusKohvwq4iM8nBspdJRQ+6Rk5PDkCFDWLhwIX5+fmRnZ1O/fn369+/Pww8/zMGDBzl06FCJA/yhQ4c4c+ZMie0FBgbSqlWrgmXhwoWldkoHBwfrJDpK2aC8UUPOXBEUPurmAJ+IyGq3RKZsU69ePWJiYoiPjy8ooX3mzBm++eYbvvnmm4L1goKCCg7u/fr1K3KwL7w0atSoyPbj4uJ46KGHyMjIKPJ6x44dycrKKijJoZSynzNXBIFAloicy3vuC9QXkcxqiK8EvSJwnxYtWpCaWrKaR1BQEJs2baJly5YuHbBHjBjBggULCg78YWFhbNu2jR49evD5558TEhLiSvhKqUpw6T4CYBnQoNDzBsC37ghM2ausyqmvv/46oaGhLp+1x8XFERwcjDGGFi1asGHDhoL7GaKioliyZIlL21dKuYczicBfRE7lP8l7HOC5kFR18XTl1NJqMN14440kJCTQunVrrrvuOl5++WVyc3Pdsj+lVNU4kwgyjDFR+U+MMT0AvTW1jih+1j5z5ky3br+0GkwdOnRg3bp1jBw5kmeeeYYbb7yR9PR0t+5XKeU8ZxLBI8BnxpiVxphVwKdYxeRUHWBX5dTAwEBmzZrFO++8w+LFi+nZsydbt26tln0rpYqqsLMYwBjjB1yW9/R/IpLt0ajKoZ3Fdc+aNWsYNmwYx44d47333uOPf/yj3SEpVee41FlsjHkACBSRRBFJBBoaY/7k7iCV97ryyivZuHEjvXv35o477uCBBx4ocjOaUsqznGkaultEChpwReQYcLfnQlLeqGXLlnz77bc8/vjjTJs2jQEDBtg+f4IWzFPewplE4Ft4Upq8+wgu8FxIylvVq1ePqVOn8tlnn5GYmEhUVBTLly+3JZb8gnnJycnExsaWuDFOqbrEmUSwGPjUGHO1MeZqrJnEvvZsWMqbDR06lB9++IGmTZsycOBAXn31Vap74roxY8aQmprqsYJ5erWhahJnEsGTwH+B+/KWnyh6g5lSbtepUyd++OEHhgwZwpNPPsnQoUM5ceJEtex72rRpBXdEg1Uwb/78+UyaNInExEQOHDhAZmZmlZNTdVxtaKJRleHsqKHuwG3AcGAX8LmIvOvh2Eqlo4a8i4jw5ptv8sQTT9C+fXu+/PJLwsPD3bb9I0eOsHnzZjZt2lSw7Nixw6nP+vn5ERQURFBQEE2aNHH68aOPPsrixYsLSm/ceOONzJkzx23fKSMjg/DwcPbt20e7du10HggFlD9qqMxEYIy5FBiZtxzGun/gcRGxtUCMJgLv9N133zF8+HAyMjKIi4tj+PDhJCUlMWLECD799NMiN6yV5dChQ0UO+Js2bWLPnj0F74eGhhIVFYWIsGjRoiJVVv39/XnggQfo3bs3x44dIz09nWPHjpX5OD09nXPnzjn13YwxBAcHF9R2atCgAf7+/lV+/Morr7B69WrOnDnjkUSjaqeqJoJcYCUwVkR25r22S0R+57FInaCJwHsdOHCA4cOHs2bNGh588EEWLFhQ6lmviLB3794iB/zNmzdz8ODBgm1deumlREVFFSzdu3fnoosuKni/eMG8yh5MRYRTp06VSBB33HEHJ0+eLLF+/fr1ufbaa8nKyiIrK4vTp0+X+djZBJMvICCAd955R+eB8HJVTQQ3AbcCfbE6jOcAH4hImKcCdYYmAu929uxZHn/8cd555x2MMYgI9evXJyoqin79+hUc+I8ePQqAj48P4eHhRQ76Xbt2pXHjxuXux1PNK6WV5w4ICODdd991usZTTk5OmUni2muvLbVcR5MmTTh2TCcW9GblJQJEpNwFCMTqH1gIZADTgT9U9DlPLT169BDl3WbOnCn169cXrAmTChYfHx+JioqScePGybRp02TdunWSkZFR5f0kJiZKRESEJCYmujF6keHDh4u/v78A4u/vLyNGjHDbtmfOnCmBgYFFfhdjjAAycOBAWb9+vdv25Qme+s2VCJAgZR3ny3qj1JUhCLgHWFaZz7lz0USggoODSyQBQJo3b253aE45deqUtGvXTowxEhISIqdOnXLr9osnmqFDh8obb7whzZs3F0AGDx4sW7dudes+3cHTv4u3c1siqAmLJgJV2llvQECAxMXF2R2a0zx55lvWAfXkyZPy8ssvy4UXXijGGBk5cqRs377d7fuvKk9eKSlNBKoO0oNG+cpLNEePHpVJkyZJQECA+Pr6ytixYzSfd+4AABkQSURBVGXPnj02RHneu+++W6K5LyAgQGbOnGlrXHVJeYnAqfsIahLtLFagY+XdISUlhcmTJzN9+nQA7r33Xp566ilatmzp8X2LCD///DPx8fHEx8ezYsWKUtdr3Lgxx44dw8fHmXtfVXlcnapSqRrHrnkU6pIWLVrw1ltvsXPnTkaPHs20adNo3749kyZNKhh15U5ZWVksXryY8ePH0759e8LDw5kwYQJHjhwhJiamxNSoxhhOnDhB165dmT9/PrXtpLVWKetSoaYu2jSklGds375dbrvtNjHGSOPGjeXFF1+UEydOuLTNvXv3yvTp0+X666+XBg0aCCANGjSQG264QaZPn16kSap4c9/w4cNlzpw5cumllwogvXr1kiVLlkhubq6rX9UroX0ESiln/fjjj3LTTTcJIM2aNZPXX39dMjMzC94vr/8hOztbVq5cKRMnTpTOnTsXtPeHhYXJgw8+KF9//bWcPn261P2W1cmdnZ0tM2fOlHbt2gkgAwYMkFWrVnnmy9dhmgiUUpW2fv16ueaaawSQ1q1by/Tp0+Xo0aMlDtaHDx+WWbNmyciRIyUoKEgAqVevnjgcDpk6daokJyc7fRZfXpLJysqSd955R1q0aCGAxMTEyKZNm9z9tessTQRKqSpbsWKF9O3bt2Akj5+fX8HBvmnTpuLj4yOABAcHy+jRo2Xu3LmSnp7usXhOnTolU6ZMKUg6Q4cOleTkZI/tr67QRKCUcklubq488sgjBQf9/MXHx0cGDx4s69evl3PnzlVrTOnp6fLss89Kw4YNxcfHR+644w7ZtWtXtcZQWE2/K1oTgVLKZWXd0R0cHGxrXKmpqfLYY4+Jv7+/+Pn5yf333y8HDhyo1hiq465oVxNNeYlAh48qpZwyefLkEsN0AwICmDJlik0RWZo3b85rr73Gzp07GTduHDNmzKB9+/Y8/vjjHD58uMi6npqwx9Mz2nl6MiO9oUwp5TRXy3NXh127dvHCCy8wa9YsAgICePTRR3n00UepV69elW9CzM7OJiUlhYMHD5ZY1q9fz08//URubm7B+sYYmjVrVjDHhCvzS/j7+zN58mRWr17N2bNnq/y7V6kMdU2liUAp+9SmO7q3bdvGs88+y7x58wgKCuLiiy9m+/btRZJYXFxcqQf34kvxKwuwDvbNmzfn6NGj5OTklHi/fv36xMTEVDi/RFZWFmfPnq3Ud6vKHBOaCJRSblPZmeHstmnTJkaPHk1iYqJT69erV4+WLVvSqlWrcpfg4GD8/PzcMsdEbm5uQXIoniyuueaaUueSCA4OJiUlxbkfARfnI3BlAQYB/wN2AhNLef9NYEvesh1Ir2ib2lmslKqssjq6AwMD5Z///KcsXrxYtm7dKqmpqVUa/VTdc0xUpdoudowaAnyBX4DfARcAW4HwctYfD8RVtF1NBEqpyvJ06fLqnmOiKommvETgyVFDvYGdIrJLRM5iTXV5YznrjwQ+8WA8SikvNWbMGGJjYwsK2/n7+3PDDTc43XRTEU8XQYyLiyM4OBhjDC1atGDmzJlu3b4nE0EbYF+h5/vzXivBGBMChAH/9WA8Sikv5umDaUREBImJiR7pN/F0oqkp9xHcCswTkXOlvWmMuccYk2CMSUhLS6vm0JRSdUFtL13uyUTjyURwALi40PO2ea+V5lbKaRYSkfdFpKeI9GzevLkbQ1RKeYvZsyE2NoLk5ERiYyOYPdvuiJw3ezaEhoKPj/XX3bHXc+/mitgAdDDGhGElgFuB24qvZIzpCAQBaz0Yi1LKi82eDffcA5mZ1vM9e6znALffbl9czqiO2D12RSAiOcCDwBJgGzBXRJKMMS8aYwYXWvVWYE5er7ZSSrlNbi7s3w+PPXb+QJovMxOeftqeuCrj6ac9H7veUKaUqhFmz7YObnv3Qrt28MorFZ/xisCxY7B7N+zaZf3NX3btss6ey7tp1xgrWdRkPj7W9yyusrGXd0OZJ5uGlFLKKeU1fwwZAr/+WvJgn//4xImi27roIggLg27d4OabrcfPPQepqSX326yZR7+WS44cgUcfLT0JgJUs3UUTgVLKdmU1f9xxB4waVfT1Bg2sDtPf/Q769bMO9GFh1vOwMGjcuOT2GzWyEkvjzIPM4VZG8CmppiVpadZVx1tvQU0ZhyICn38ODzwAR4/CTTfB0qVFf5+AAOuKyV00ESilbLd3b+mv5+bCSy8VPdC3aGE1i1RGfhNT7n0v8ftTq5ja8EVy353Gnj3w8svWgfadd2DEiMpv250OHrQSwJdfQo8eVlxdu1at2awytI9AKWWbtDSYPBnefLP090NCrGYhlzVoAFlZJV/39ycp4TRjx8L69XDDDTBtGrRt64Z9VoII/POfVlPQmTPw4ovw5z9DPTeeqpfXR1BTbihTSnmR9HT4y1+sM/y334b+/a1jdWFubf7YtQtuu83aaP7Gb78ddu8mIgJWr4Y33oBvv4WICHj//errRN69G/7wBxg71jr737oVJkxwbxKoiCYCpeoYT9985IpTp+Cvf7USwCuvwPXXQ3IyfPcdzJhhXQEYY/19/303Nn+0amV1HmRlgb+/9bdxY2jZEgBfX+sMPDERevaEe++Fq6+GnTvdtP9SnDtnJcHISOtqZPp0WL4cLr3Uc/ssU1nV6GrqotVHlSrbrFkiAQFWXeH8JSDAet1Op0+LvPmmSHCwFdP114ts3lzNQdx8s8if/iSyZYv19+abS10tN1dkxgyRxo1FGjQQee01kexs94aSlCRyxRXWbxETI7J3r3u3Xxp08nqlvENISNEkkL+EhNgTz9mzIu+9J9K2rRXH1VeLrF1rTyyVtX+/yODBVty9eon8+KPr2zxzRuSll0QuuECkaVMrQefmur5dZ5SXCLRpSKk64swZa/x9afbssZpgqmtsyLlzMGsWdOpkNbO0bQvLlllt8H36VE8MrmrTBubPh08/tTqso6Ks+xHOnKna9hISoFcveOYZ696I5GSr6cvOUUr5NBEoVcvl5EBcHFx2WfnrRURA69bWwScuzk2jcYoRgS++sDo9//hHaNgQFi6ENWvgqqvcvz9PMwaGD4dt2+DWW63RPD16WG36zjp9Gp54Ai6/HA4fhq++gk8+geBgz8VdWZoIlKqlcnNhzhzrAD92rHVD1JNPnh8Yky8gwBoRM2MGOBzWWfnYsVaHbfv2cPfd1nYqMf1tCSKweLF1xnvLLVZy+vRT2LTJ6hCuCWe9rmjaFD7+GOLj4fhxuOIKa6hnoWmKS/Xdd9ClC0ydav3mSUkweHD5n7FFWW1GNXXRPgLl7XJzRb76SqRLF6v9OjJS5Msvz7c1z5pl9QkYY/0t3lGcmyvy008ib79ttYE3bny+LyEyUuThh63tp6eX3Hdp2/7uO5F+/azPh4aK/POf7u9crUmOHxe5/37r+4aFiXz7bcnfZcYMkfvus9b53e9Eli2zO+ry+wj0hjKlapFly6w7TNevh0sugRdesO6G9fWt+jZzcmDzZmvb//0vrFplNWf4+FhDKa++2mrW2bcPHnywaKkDHx/ryqRVK+u+gHHj4IILXP+etcH331vfd8cO6/c/V2haLWOs1Proo9ad0cWv0uxQ3g1lmgiUqgXWrLEOtMuXw8UXw7PPwujR4Ofn/n2dOQPr1lmJYdky+OEHK1mUpUkTOHCgZhzsqtvp09atCMUL34H1+sGD1R9TWfTOYqUqqabclLV5M8TGQt++Vvvy22/D9u3WmagnkgBA/fowYIDVMbp6tVX4bNGistc/ftw7kwBYd0OfPFn6e670uVQ3TQRKFZNfEnnPHuvyPr8kcnUmg23bYNgwa8ji2rVWPZ5du+Chh6wbY6tTo0Zw3XXW3b6lcWc55NqorO9fm34XTQRKFVMdM0KVZdcuq8knMtIahfPMM9ZrEyeC3XOtv/JK6SOS3FkOuTaqC7+LlqFWqpiySiLv2WNNdJJfDjl/CQ11vWnkwAGrHPIHH1jFxv78Z2soaE2pkQ/n6/54shxybVQXfhftLFaqkPnzrXHwpVWebNDAOvDv3m11EhbWsmXJCVLyH7dtW3RUT+Ha8m3aQOfOVidwTo41pv/pp63XlXInnapSqQqkpMD48fDZZ9aonLS0ouXrAwLOV8MUsdYvbZ7c1autm7MKJ5J69ayzxLAw6/VVqyA723pv/35r6dcP/vUvax2lqpsmAuXVRKyaOI88YpVIfuUVqxb83LllX+obY10BtGxp3WFaXHa2Nea+tDl2ExJKv9rYu1eTgLKPNg3VcJ6eos6b7d0L990HX38NV14JM2dCx46e3aePT+mF34ypvolQlHfS+whqqZowjLEuys21piOMiLDuDv3b32DlSs8nAagbQw1V3aOJoAazcxhjXbV9u1V47YEHrGadxESrb8Cnmv4l1IWhhqru0URQg5U1jLGs12uamnJ3Llgjcv7v/6xKkD/9ZE0UvmSJFVd1uv12q9PZY1MyKlUFmghqsIYNS39dxLUJMqpDTWrW2rLFqgU/caJVrmHbNrjzTvtKI99+uzUXQG6u9VeTgLKbJoIa6r33rBom9YqN62rQwKo7U5UJMqrTxImlN2s9+mjJMfiekpVlNaP17GndsDVvHnz+ecF85UqpPJoIaqAlS6w27Ouus2aSKtyMMGOGNQ79P/+p3AQZ1SUjw6qLs39/6e+nplrVKqOjrTtp16w5P6bendasge7d4a9/tWbKSk62bhRTSpWirIkKaupS1yem+ekna6KQzp2tCTDKU9oEGXY5fVrkrbdEgoOteBo0OD/ZSeElOFjkscdEune3JvEAkYYNRWJiRF5/XWTzZpFz56oex8mTIuPHn58gZMkSt31FpWo1ypmYxvYDe2WXupwIDh2yDl4tW4rs2eP851asELnkEuu/5rhxIseOeSzEEs6eFXn/fZG2ba39R0eLrFljzdgUEFA0CQQEFJ0t6/BhkXnzrGR22WXn12vaVGToUJFp00T+97/zM29VZMmS87NEjR9vJQWllEUTQS2QkSHSu7d1Jr1hQ+U/n5kp8sQTIj4+Iq1aicyf7/4YC8vJsQ7q+Qno8stLXpFUNGVicfv2iXz0kcjo0ecTC1iP77hD5MMPrXWKb7tt2/NTJV52mciqVe7/vkrVdpoIarhz50RuucU6qH35pWvb2rDh/Fy2I0aIpKS4J8Z8ubkiX3whEhFh7aNLF5EFC5w/a6/MfrZvF/nHP0SGDRNp1ux8YmjRQqRePSnR7DR4sNVEpZQqqbxEoJ3FNcBTT1mjWaZOhZtucm1bPXta9Wxeegm+/BI6dbJq6YiLlURErE7s3r1hyBCrg3fOHGsGrRtucP9QTGOgQwe4916r7k9KCmzdCm+8YU0LWNrUiVu3Vv+kLUrVCWVliJq6VOWKoLJNFNVpxgzrbPbee91/Vp2UJNKnj7X9mBiRvXurtp3vvz/f9BISIhIXJ5Kd7dZQKyW/k7n4Yox9MSlV0+HNTUPOdFra5dtvrSaOP/zB6nT1hJwcazRPQIA1OmfaNOdH5SQkiFx7rfWbtWwp8u67IllZnomzMkJCSk8EISF2R6ZUzeXViaCmHjSSkkQuvNBqa09P9/z+du0SGTjQ+u79+lmjccqSmCgyZIi17kUXibz6qtWZXVPU5OSuVE1VXiKo830ENbFeT2qqVerA3x/i4+HCCz2/z7AwWLrUKrX844/QtSu8+ip8/PH5ekBt2sDvf2/NmPXNN/D881Yd/QkTXJ+K0Z20Xo9S7lXn5yMIDbXq3JRm6lRrQpLiZRw86fRpuOoqq2NzxQqr87W6/fabdefy/PnWgbT4/wLXXw8ffghNm1Z/bEopz/Dq+QhKK/vboAFERVlnuldcYZ0hV4fcXKvY2bp11pm4HUkAoHVr+OILaNas9NFEP/2kSUApb+LRRGCMGWSM+Z8xZqcxZmIZ6ww3xiQbY5KMMf92dwylNSPMmGENsfz0U+tqoUeP6qnm+cwz1lDI//s/++veGANHjpT+Xm0pc62UcpOyOg9cXQBf4Bfgd8AFwFYgvNg6HYDNQFDe8+CKtuvuG8oOHxYZNcrqcAwPF1m71q2bLxAXJwUlINw9TLSqampHulLK/bCps7g3sFNEdonIWWAOcGOxde4G/i4ix/KSUqoH4ylV06ZWM018vHWj0pVXur+a5/LlVi3+gQOtKRLtqoNfnM6WpZQCzzYNtQH2FXq+P++1wi4FLjXGrDbGrDPGDCptQ8aYe4wxCcaYhLS0NI8EGxMDSUnWZOZvvmmNnFm2zPXt/vyzdSfupZfCZ5+Bn5/r23QXHX2jlAL7O4vrYTUPOYCRwAxjTJPiK4nI+yLSU0R6Nm/e3GPBNG5snbF/9501kmjgQBg3DtLTq7a9tDRrmKifnzV/QJMS38x+OluWUsqTieAAcHGh523zXitsP7BARLJFZDewHSsx2Kp/f2t45xNPWHPbhofDV19VbhtZWVbdoN9+gwULrHH8SilVE3kyEWwAOhhjwowxFwC3AguKrTMf62oAY0wzrKaiXR6MyWkNGlije9avh+bNrYP6iBFW8bOKiMCYMdYsWR99BH36eD5epZSqKo8lAhHJAR4ElgDbgLkikmSMedEYMzhvtSXAEWNMMrAcmCAiZQxqtEfhap7z51tXBxVV83zuOfjkE2uaxGHDqi9WpZSqijp/Z7E7JSdbfQZr11rzCf/jH9CuXdF1PvoIRo+2rgg++KDmjBBSSnk3r76z2J3Cw2HlSnj7batDOSICpk+3rhDy6/WMHm3NATB9uiYBpVTtoImgknx94aGHIDHRavv/05+sg/+ePeebi3791RoqqpRStYEmgirKr+bZtKk19LKw06fh6aftiUsppSpLE4ELjIGjR0t/T+v1KKVqC00ELireWVzR60opVdNoInCR1utRStV2mghcpPV6lFK1XTXOzVV33X67HviVUrWXXhEopZSX00SglFJeThOBUkp5OU0ESinl5TQRKKWUl6t11UeNMWnAHrvjKEMz4LDdQVRRbY29tsYNGrtdvDX2EBEpdYrHWpcIajJjTEJZZV5rutoae22NGzR2u2jsJWnTkFJKeTlNBEop5eU0EbjX+3YH4ILaGnttjRs0drto7MVoH4FSSnk5vSJQSikvp4lAKaW8nCYCFxljLjbGLDfGJBtjkowxD9sdU2UZY3yNMZuNMf+xO5bKMMY0McbMM8b8bIzZZoy5wu6YnGWM+XPe/y+JxphPjDH+dsdUFmNMnDEm1RiTWOi1i4wx3xhjduT9DbIzxrKUEfvUvP9nfjTGfGmMaWJnjKUpLe5C7z1mjBFjTDN37U8TgetygMdEJBzoAzxgjAm3OabKehjYZncQVfA2sFhEOgJdqSXfwRjTBngI6CkikYAvcKu9UZXrQ2BQsdcmAstEpAOwLO95TfQhJWP/BogUkS7AdmBSdQflhA8pGTfGmIuBPwBunQxXE4GLROSgiGzKe3wS62DUxt6onGeMaQvEAh/YHUtlGGMuBPoDMwFE5KyIpNsbVaXUAxoYY+oBAcBvNsdTJhH5Hig+O/eNwL/yHv8LuKlag3JSabGLyFIRycl7ug5oW+2BVaCM3xzgTeAJwK2jfDQRuJExJhToDqy3N5JKeQvrf6xcuwOppDAgDfhnXrPWB8aYQLuDcoaIHABewzqrOwgcF5Gl9kZVaS1E5GDe40NACzuDccEY4Gu7g3CGMeZG4ICIbHX3tjURuIkxpiHwOfCIiJywOx5nGGOuB1JFZKPdsVRBPSAKmC4i3YEMam7zRBF57ek3YiWz1kCgMWaUvVFVnVhj0GvdOHRjzNNYTbuz7Y6lIsaYAOAp4FlPbF8TgRsYY/ywksBsEfnC7ngqoS8w2BjzKzAHuMoYM8vekJy2H9gvIvlXX/OwEkNtMBDYLSJpIpINfAFcaXNMlZVijGkFkPc31eZ4KsUYcydwPXC71I6bqdpjnThszfv32hbYZIxp6Y6NayJwkTHGYLVTbxORN+yOpzJEZJKItBWRUKzOyv+KSK04MxWRQ8A+Y8xleS9dDSTbGFJl7AX6GGMC8v7/uZpa0tFdyAJgdN7j0cBXNsZSKcaYQVjNoYNFJNPueJwhIj+JSLCIhOb9e90PROX9O3CZJgLX9QX+iHU2vSVvibE7KC8xHphtjPkR6Ab81eZ4nJJ3FTMP2AT8hPXvsMaWPTDGfAKsBS4zxuw3xowFpgDXGGN2YF3hTLEzxrKUEfu7QCPgm7x/r/+wNchSlBG35/ZXO66KlFJKeYpeESillJfTRKCUUl5OE4FSSnk5TQRKKeXlNBEopZSX00SglIuMMacKPY4xxmw3xoTYGZNSlVHP7gCUqiuMMVcDfwOuFZE9dsejlLM0ESjlBsaY/sAMIEZEfrE7HqUqQ28oU8pFxphs4CTgEJEf7Y5HqcrSPgKlXJcNrAE8WgZAKU/RRKCU63KB4UBvY8xTdgejVGVpH4FSbiAimcaYWGClMSZFRGbaHZNSztJEoJSbiMjRvBLH3xtj0kRkgd0xKeUM7SxWSikvp30ESinl5TQRKKWUl9NEoJRSXk4TgVJKeTlNBEop5eU0ESillJfTRKCUUl7u/wGhuQ1pp/pPyAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using different distance functions"
      ],
      "metadata": {
        "id": "dV2FEAJB6Mbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### running KNN on hep_df data for all data\n",
        "\n",
        "# splits the data\n",
        "x_train, y_train, x_test, y_test = train_test_split(hep_df)\n",
        "\n",
        "def distTest(k, function, x_train, y_train, x_test, y_test):\n",
        "  # creates a new KNN model using euclidean distance\n",
        "  knn_model = KNN(K = k, dist_fn=function)\n",
        "  # fits the model to the training data, then tests the model on the test\n",
        "  # data for K = 3\n",
        "  class_prob, knn_arr = knn_model.fit(x_train, y_train).predict(x_test)\n",
        "  # outputs an array of the most likely class labels for each instance in x_test\n",
        "  class_pred = np.argmax(class_prob, axis = -1)\n",
        "  # finds the accuracy of the model\n",
        "  accuracy = evaluate_acc(y_test, class_pred)\n",
        "  return accuracy\n",
        "\n",
        "euclid1_accuracy = distTest(k=1, function = euclidean, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "manhat1_accuracy = distTest(k=1, function = manhattan, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "euclid3_accuracy = distTest(k=3, function = euclidean, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "manhat3_accuracy = distTest(k=3, function = manhattan, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "euclid5_accuracy = distTest(k=5, function = euclidean, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "manhat5_accuracy = distTest(k=5, function = manhattan, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "print(\"k = 1\")\n",
        "print(\"The accuracy of the euclidean model is: \" + str(round((euclid1_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the manhattan model is: \" + str(round((manhat1_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "print(\"k = 3\")\n",
        "print(\"The accuracy of the euclidean model is: \" + str(round((euclid3_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the manhattan model is: \" + str(round((manhat3_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "print(\"k = 5\")\n",
        "print(\"The accuracy of the euclidean model is: \" + str(round((euclid5_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the manhattan model is: \" + str(round((manhat5_accuracy * 100), 2)) + \"%\")"
      ],
      "metadata": {
        "id": "dTpwaTTo6gmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### using different dist functions on mess_df\n",
        "x_train, y_train, x_test, y_test = train_test_split(mess_df)\n",
        "\n",
        "euclid1_accuracy = distTest(k=1, function = euclidean, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "manhat1_accuracy = distTest(k=1, function = manhattan, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "euclid3_accuracy = distTest(k=3, function = euclidean, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "manhat3_accuracy = distTest(k=3, function = manhattan, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "euclid5_accuracy = distTest(k=5, function = euclidean, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "manhat5_accuracy = distTest(k=5, function = manhattan, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "print(\"k = 1\")\n",
        "print(\"The accuracy of the euclidean model is: \" + str(round((euclid1_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the manhattan model is: \" + str(round((manhat1_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "print(\"k = 3\")\n",
        "print(\"The accuracy of the euclidean model is: \" + str(round((euclid3_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the manhattan model is: \" + str(round((manhat3_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "print(\"k = 5\")\n",
        "print(\"The accuracy of the euclidean model is: \" + str(round((euclid5_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the manhattan model is: \" + str(round((manhat5_accuracy * 100), 2)) + \"%\")"
      ],
      "metadata": {
        "id": "MiXMxxnSBNy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Boundaries"
      ],
      "metadata": {
        "id": "MDU_px5crtld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To plot decision boundaries, we will use the best two features to fit the model and predict it. We do so because it would not be possible to plot all features on a 2d graph. Alternatively we could have chosen to use dimensionality reduction but we believe this serves to better illustrate the effects of the most important features."
      ],
      "metadata": {
        "id": "RRRMYUiGY0bv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZenKHiL01T_"
      },
      "outputs": [],
      "source": [
        "### plotting decision boundary\n",
        "#Here we use a subset of the data to only include the two best features that were found earlier\n",
        "\n",
        "x_db = hep_df[[\"ALBUMIN\", \"BILIRUBIN\"]].to_numpy()\n",
        "y_db = np.ravel((hep_df.iloc[:, -1:]).to_numpy())\n",
        "\n",
        "\n",
        "def dbDraw(x,y, x0label, x1label):\n",
        "  x_tr, x_tst, y_tr, y_tst =   train_test_split(x, y, test_size=0.2, random_state=11)\n",
        "\n",
        "  #we can make the grid finer by increasing the number of samples from 200 to higher value\n",
        "  x0v = np.linspace(np.min(x[:,0]), np.max(x[:,0]), 200)\n",
        "  x1v = np.linspace(np.min(x[:,1]), np.max(x[:,1]), 200)\n",
        "\n",
        "  # to features values as a mesh  \n",
        "  x0, x1 = np.meshgrid(x0v, x1v)\n",
        "  x_all = np.vstack((x0.ravel(),x1.ravel())).T\n",
        "\n",
        "  #Number of classes:\n",
        "  C = np.max(y)+1\n",
        "  # Getting coloring for y\n",
        "  y_train_prob = np.zeros((y_tr.shape[0], C))\n",
        "  y_train_prob[np.arange(y_tr.shape[0]), y_tr] = 1\n",
        "\n",
        "  model = KNN(K = 1)\n",
        "  #to get class probability of all the points in the 2D grid\n",
        "  y_prob_all, _ = model.fit(x_tr, y_tr).predict(x_all)\n",
        "  y_pred_all = np.argmax(y_prob_all,axis=-1)\n",
        "\n",
        "  #lastly we need to graph the results\n",
        "  plt.scatter(x_tr[:,0], x_tr[:,1], c=y_tr, marker='o', alpha=1)\n",
        "  plt.scatter(x_all[:,0], x_all[:,1], c=y_pred_all, marker='.', alpha=.01)\n",
        "  plt.ylabel(x1label)\n",
        "  plt.xlabel(x0label)\n",
        "  plt.show()\n",
        "\n",
        "dbDraw(x_db, y_db, \"Albumin\", \"Bilirubin\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_db = mess_df[[\"2\", \"8\"]].to_numpy()\n",
        "y_db = mess_df[\"Class\"].to_numpy()\n",
        "\n",
        "dbDraw(x_db, y_db, \"2\", \"8\")"
      ],
      "metadata": {
        "id": "o3U54mDkozgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importance"
      ],
      "metadata": {
        "id": "UH0AJAnX-rl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For feature importance we will employ a simple approach. We will first train a model using a training set. We will then use that model predict the labels of the training set. Afterwards we can fit a random forest (could be linear regression as well) model on the training input and the predicted output. From there we can extract the importances of this new model to see how the original model weighs the importance of each individual to make its prediction.\n",
        "Essentially\n",
        "$$knn.fit(x_{train}, y_{train}).predict(x_{train}) = \\hat y, \\space importance = RandomForest.fit(x_{train}, \\hat y).featureImportances$$"
      ],
      "metadata": {
        "id": "Zy26nHsk-vA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we use k!=1, otherwise y_pred = y\n",
        "def knnFeatImportance(x_train, y_train):\n",
        "  knn = KNN(K = 3)\n",
        "  y_pred = knn.fit(x_train,y_train).predict(x_train)\n",
        "  RF_find_featuresXY(x_train, y_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "X1FlrtnJBvE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hep"
      ],
      "metadata": {
        "id": "xnYPuvhxDdSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mess"
      ],
      "metadata": {
        "id": "7m5jNzGnDdjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DT experiments"
      ],
      "metadata": {
        "id": "MPKaxl_Ynx2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline accuracy tests"
      ],
      "metadata": {
        "id": "j_M_9TNcpzar"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZzVFXwC2A6q"
      },
      "outputs": [],
      "source": [
        "### running DT on hepatitis.data\n",
        "\n",
        "x_train, y_train, x_test, y_test = train_test_split(df = hep_df)\n",
        "\n",
        "dt_model = DecisionTree(max_depth = 10)\n",
        "\n",
        "# fits the model to the training data, then tests the model on the test\n",
        "# data for K = 3\n",
        "class_probs = dt_model.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "# outputs an array of the most liekly class label for each instance in x_test\n",
        "class_pred = np.argmax(class_probs, axis = 1)\n",
        "\n",
        "# finds the accuracy of the model\n",
        "accuracy = evaluate_acc(y_test, class_pred)\n",
        "\n",
        "# creates boolean arrays to represent correct and incorrect predictions\n",
        "correct_pred = class_pred == y_test\n",
        "incorrect_pred = np.logical_not(correct_pred)\n",
        "\n",
        "print(accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2rfyd8QnXCD"
      },
      "outputs": [],
      "source": [
        "### running DT on messidor_features.arff\n",
        "\n",
        "x_train, y_train, x_test, y_test = train_test_split(df = mess_df)\n",
        "\n",
        "dt_model = DecisionTree(max_depth = 10)\n",
        "\n",
        "# fits the model to the training data, then tests the model on the test\n",
        "# data for K = 3\n",
        "class_probs = dt_model.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "# outputs an array of the most liekly class label for each instance in x_test\n",
        "class_pred = np.argmax(class_probs, axis = 1)\n",
        "\n",
        "# finds the accuracy of the model\n",
        "accuracy = evaluate_acc(y_test, class_pred)\n",
        "\n",
        "# creates boolean arrays to represent correct and incorrect predictions\n",
        "correct_pred = class_pred == y_test\n",
        "incorrect_pred = np.logical_not(correct_pred)\n",
        "\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing different values for maximum tree depth"
      ],
      "metadata": {
        "id": "JVBxQIi_juaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hep data\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(1234)\n",
        "X = hep_df.iloc[:, :-1].to_numpy()\n",
        "Y = np.ravel((hep_df.iloc[:, -1:]).to_numpy())\n",
        "\n",
        "def testDifDepth(x, y, saveName):\n",
        "  #now we can divide the data into 3 sections: training, validation, testing\n",
        "\n",
        "  x_tr, x_tst, y_tr, y_tst =   train_test_split(x, y, test_size=0.2, random_state=11)\n",
        "  x_tr, x_valid, y_tr, y_valid = train_test_split(x_tr, y_tr, test_size=0.2, random_state=11)\n",
        "  \n",
        "\n",
        "  ### choise of max depth\n",
        "  model_choices=[]\n",
        "  train_acc = []\n",
        "  valid_acc = []\n",
        "\n",
        "  n_train = y_tr.shape[0]\n",
        "  n_valid = y_valid.shape[0]\n",
        "\n",
        "  for k in range(1, 15):\n",
        "      dt = DecisionTree(max_depth=k, cost_fn=cost_gini_index) # create a DT object (OOP)\n",
        "\n",
        "      y_train_tr_prob = dt.fit(x_tr, y_tr).predict(x_tr)\n",
        "      y_train_tr_pred = np.argmax(y_train_tr_prob, axis=-1)\n",
        "      acc_tr = np.sum(y_train_tr_pred == y_tr)/n_train\n",
        "\n",
        "      y_train_va_prob = dt.fit(x_tr, y_tr).predict(x_valid)\n",
        "      y_train_va_pred = np.argmax(y_train_va_prob, axis=-1)\n",
        "      acc_va = np.sum(y_train_va_pred == y_valid)/n_valid\n",
        "\n",
        "      model_choices.append(k)\n",
        "      train_acc.append(acc_tr)\n",
        "      valid_acc.append(acc_va)\n",
        "\n",
        "  # use the best K to predict test data\n",
        "  best_depth = model_choices[valid_acc.index(max(valid_acc))]\n",
        "  dt = DecisionTree(max_depth=best_depth, cost_fn=cost_gini_index)\n",
        "  y_test_prob = dt.fit(x_train, y_train).predict(x_tst)\n",
        "\n",
        " \n",
        "\n",
        "  y_test_pred = np.argmax(y_test_prob, axis=-1)\n",
        " \n",
        "  test_accuracy = np.sum(y_test_pred == y_tst)/y_tst.shape[0]\n",
        "  print(f'best depth = {best_depth}, test accuracy = {test_accuracy}')\n",
        "\n",
        "  plt.plot(model_choices, train_acc, marker='d', color='black', label='training')\n",
        "  plt.plot(model_choices, valid_acc, marker='o', color='blue', label='validation')\n",
        "  plt.plot(best_depth, test_accuracy, marker='*', color='red', label='testing')\n",
        "  plt.xlabel(\"Tree depth\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.savefig(saveName,dpi=300,bbox_inches='tight')\n",
        "\n",
        "testDifDepth(X, Y, 'hep_DT_chooseDepth.png')"
      ],
      "metadata": {
        "id": "PRlkQ23WFXTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Messador data\n",
        "np.random.seed(123)\n",
        "X = mess_df.iloc[:, :-1].to_numpy()\n",
        "Y = np.ravel((mess_df.iloc[:, -1:]).to_numpy())\n",
        "\n",
        "testDifDepth(X, Y, 'mess_DT_chooseDepth.png')"
      ],
      "metadata": {
        "id": "OSZoKpbMED9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(123)\n",
        "x = hep_df.iloc[:, :-1].to_numpy()\n",
        "y = np.ravel((hep_df.iloc[:, -1:]).to_numpy())\n",
        "#now we can divide the data into 3 sections: training, validation, testing\n",
        "\n",
        "x_tr, x_tst, y_tr, y_tst =   train_test_split(x, y, test_size=0.2, random_state=11)\n",
        "x_tr, x_valid, y_tr, y_valid = train_test_split(x_tr, y_tr, test_size=0.2, random_state=11)\n",
        "\n",
        "\n",
        "### choise of max depth\n",
        "model_choices=[]\n",
        "valid_acc = []\n",
        "\n",
        "n_valid = y_valid.shape[0]\n",
        "\n",
        "for k in range(1,15):\n",
        "    dt_model = DecisionTreeClassifier(max_depth = k ) # create a KNN object \n",
        "    fit = dt_model.fit(x_tr, y_tr)\n",
        "    y_train_va_prob = fit.predict(x_valid)\n",
        "    y_train_va_pred = np.argmax(y_train_va_prob,axis=-1)\n",
        "    accuracy = np.sum(y_train_va_pred == y_valid)/n_valid\n",
        "    model_choices.append(k)\n",
        "    valid_acc.append(accuracy)\n",
        "\n",
        "# use the best K to predict test data\n",
        "best_valid_K = model_choices[valid_acc.index(max(valid_acc))]\n",
        "dt = DecisionTreeClassifier(max_depth=best_valid_K)\n",
        "y_test_pred  = dt.fit(x_tr, y_tr).predict(x_tst)\n",
        "\n",
        "test_accuracy = np.sum(y_test_pred == y_tst)/y_tst.shape[0]\n",
        "print(y_test_pred)\n",
        "print(y_tst)\n",
        "print(f'best K = {best_valid_K}, test accuracy = {test_accuracy}')\n",
        "\n",
        "plt.plot(model_choices, valid_acc, marker='o', color='blue', label='validation')\n",
        "plt.plot(best_valid_K, test_accuracy, marker='*', color='red', label='testing')\n",
        "plt.xlabel(\"K\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('iris_KNN_chooseK.png',dpi=300,bbox_inches='tight')"
      ],
      "metadata": {
        "id": "ypPPbZcArUIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwKpJ34rJr2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using different cost functions"
      ],
      "metadata": {
        "id": "fFXfubqxJsKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### running KNN on hep_df data for all data\n",
        "\n",
        "# splits the data\n",
        "x_train, y_train, x_test, y_test = train_test_split(hep_df)\n",
        "\n",
        "def costTest(k, function, x_train, y_train, x_test, y_test):\n",
        "  # creates a new KNN model using euclidean distance\n",
        "  dt_model = DecisionTree(max_depth= k, cost_fn= function)\n",
        "  # fits the model to the training data, then tests the model on the test\n",
        "  # data for K = 3\n",
        "  class_prob = dt_model.fit(x_train, y_train).predict(x_test)\n",
        "  # outputs an array of the most likely class labels for each instance in x_test\n",
        "  class_pred = np.argmax(class_prob, axis = -1)\n",
        "  # finds the accuracy of the model\n",
        "  accuracy = evaluate_acc(y_test, class_pred)\n",
        "  return accuracy\n",
        "\n",
        "GI1_accuracy = costTest(k=1, function = cost_gini_index, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "miss1_accuracy = costTest(k=1, function = cost_misclassification, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "ent1_accuracy = costTest(k=1, function = cost_entropy, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "GI3_accuracy = costTest(k=3, function = cost_gini_index, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "miss3_accuracy = costTest(k=3, function = cost_misclassification, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "ent3_accuracy = costTest(k=3, function = cost_entropy, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "GI5_accuracy = costTest(k=5, function = cost_gini_index, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "miss5_accuracy = costTest(k=5, function = cost_misclassification, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "ent5_accuracy = costTest(k=5, function = cost_entropy, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "print(\"k = 1\")\n",
        "print(\"The accuracy of the gini model is: \" + str(round((GI1_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the missclasification model is: \" + str(round((miss1_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the entropy model is: \" + str(round((ent1_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "print(\"k = 3\")\n",
        "print(\"The accuracy of the gini model is: \" + str(round((GI3_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the missclasification model is: \" + str(round((miss3_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the entropy model is: \" + str(round((ent3_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "print(\"k = 5\")\n",
        "print(\"The accuracy of the gini model is: \" + str(round((GI5_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the missclasification model is: \" + str(round((miss5_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the entropy model is: \" + str(round((ent5_accuracy * 100), 2)) + \"%\")"
      ],
      "metadata": {
        "id": "ENCDTmzSJsKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splits the data\n",
        "x_train, y_train, x_test, y_test = train_test_split(mess_df)\n",
        "GI1_accuracy = costTest(k=1, function = cost_gini_index, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "miss1_accuracy = costTest(k=1, function = cost_misclassification, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "ent1_accuracy = costTest(k=1, function = cost_entropy, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "GI3_accuracy = costTest(k=3, function = cost_gini_index, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "miss3_accuracy = costTest(k=3, function = cost_misclassification, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "ent3_accuracy = costTest(k=3, function = cost_entropy, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "GI5_accuracy = costTest(k=5, function = cost_gini_index, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "miss5_accuracy = costTest(k=5, function = cost_misclassification, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "ent5_accuracy = costTest(k=5, function = cost_entropy, x_train = x_train, y_train = y_train, x_test= x_test, y_test=y_test)\n",
        "\n",
        "print(\"k = 1\")\n",
        "print(\"The accuracy of the gini model is: \" + str(round((GI1_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the missclasification model is: \" + str(round((miss1_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the entropy model is: \" + str(round((ent1_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "print(\"k = 3\")\n",
        "print(\"The accuracy of the gini model is: \" + str(round((GI3_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the missclasification model is: \" + str(round((miss3_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the entropy model is: \" + str(round((ent3_accuracy * 100), 2)) + \"%\")\n",
        "\n",
        "print(\"k = 5\")\n",
        "print(\"The accuracy of the gini model is: \" + str(round((GI5_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the missclasification model is: \" + str(round((miss5_accuracy * 100), 2)) + \"%\")\n",
        "print(\"The accuracy of the entropy model is: \" + str(round((ent5_accuracy * 100), 2)) + \"%\")"
      ],
      "metadata": {
        "id": "cViXVi6EMZqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Boundaries"
      ],
      "metadata": {
        "id": "MZVIe3IxqIAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To plot decision boundaries, we will use the best two features to fit the model and predict it. We do so because it would not be possible to plot all features on a 2d graph. Alternatively we could have chosen to use dimensionality reduction but we believe this serves to better illustrate the effects of the most important features."
      ],
      "metadata": {
        "id": "MMZVePyRqIAV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Osndfi-FqIAV"
      },
      "outputs": [],
      "source": [
        "### plotting decision boundary\n",
        "#Here we use a subset of the data to only include the two best features that were found earlier\n",
        "\n",
        "x_db = hep_df[[\"ALBUMIN\", \"BILIRUBIN\"]].to_numpy()\n",
        "y_db = np.ravel((hep_df.iloc[:, -1:]).to_numpy())\n",
        "print(x_db[:5])\n",
        "print(y_db[:5])\n",
        "\n",
        "\n",
        "def dbDraw(x,y, x0label, x1label):\n",
        "  x_tr, x_tst, y_tr, y_tst =   train_test_split(x, y, test_size=0.2, random_state=11)\n",
        "\n",
        "  #we can make the grid finer by increasing the number of samples from 200 to higher value\n",
        "  x0v = np.linspace(np.min(x[:,0]), np.max(x[:,0]), 200)\n",
        "  x1v = np.linspace(np.min(x[:,1]), np.max(x[:,1]), 200)\n",
        "\n",
        "  # to features values as a mesh  \n",
        "  x0, x1 = np.meshgrid(x0v, x1v)\n",
        "  x_all = np.vstack((x0.ravel(),x1.ravel())).T\n",
        "\n",
        "  #Number of classes:\n",
        "  C = np.max(y)+1\n",
        "  # Getting coloring for y\n",
        "  y_train_prob = np.zeros((y_tr.shape[0], C))\n",
        "  y_train_prob[np.arange(y_tr.shape[0]), y_tr] = 1\n",
        "\n",
        "  model = DecisionTree(max_depth= 10, cost_fn=cost_gini_index)\n",
        "  #to get class probability of all the points in the 2D grid\n",
        "  y_prob_all = model.fit(x_tr, y_tr).predict(x_all)\n",
        "  y_pred_all = np.argmax(y_prob_all,axis=-1)\n",
        "\n",
        "  #lastly we need to graph the results\n",
        "  plt.scatter(x_tr[:,0], x_tr[:,1], c=y_tr, marker='o', alpha=1)\n",
        "  plt.scatter(x_all[:,0], x_all[:,1], c=y_pred_all, marker='.', alpha=.01)\n",
        "  plt.ylabel(x1label)\n",
        "  plt.xlabel(x0label)\n",
        "  plt.show()\n",
        "\n",
        "print(len(x_db))\n",
        "print(len(y_db))\n",
        "dbDraw(x_db, y_db, \"Albumin\", \"Bilirubin\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_db = mess_df[[\"2\", \"8\"]].to_numpy()\n",
        "y_db = mess_df[\"Class\"].to_numpy()\n",
        "\n",
        "dbDraw(x_db, y_db, \"2\", \"8\")"
      ],
      "metadata": {
        "id": "HTFJlUYtqIAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importance"
      ],
      "metadata": {
        "id": "06VAZauEDmAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For feature importance we will employ a simple approach. We will first train a model using a training set. We will then use that model predict the labels of the training set. Afterwards we can fit a random forest (could be linear regression as well) model on the training input and the predicted output. From there we can extract the importances of this new model to see how the original model weighs the importance of each individual to make its prediction.\n",
        "Essentially\n",
        "$$dt.fit(x_{train}, y_{train}).predict(x_{train}) = \\hat y, \\space importance = RandomForest.fit(x_{train}, \\hat y).featureImportances$$"
      ],
      "metadata": {
        "id": "WJD8YjevDmAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dtFeatImportance(x_train, y_train):\n",
        "  dt = DecisionTree(max_depth= 10, cost_fn = cost_gini_index)\n",
        "  y_pred = dt.fit(x_train,y_train).predict(x_train)\n",
        "  RF_find_featuresXY(x_train, y_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "07wKRA2pDmAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hep\n"
      ],
      "metadata": {
        "id": "VZRCG2yPDmAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mess"
      ],
      "metadata": {
        "id": "udxXcmbcDmAd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}